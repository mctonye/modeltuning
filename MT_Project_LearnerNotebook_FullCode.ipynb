{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EaJ8AGwpM-2"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3-QehJxbp0t"
   },
   "source": [
    "### Business Context\n",
    "\n",
    "Renewable energy sources play an increasingly important role in the global energy mix, as the effort to reduce the environmental impact of energy production increases.\n",
    "\n",
    "Out of all the renewable energy alternatives, wind energy is one of the most developed technologies worldwide. The U.S Department of Energy has put together a guide to achieving operational efficiency using predictive maintenance practices.\n",
    "\n",
    "Predictive maintenance uses sensor information and analysis methods to measure and predict degradation and future component capability. The idea behind predictive maintenance is that failure patterns are predictable and if component failure can be predicted accurately and the component is replaced before it fails, the costs of operation and maintenance will be much lower.\n",
    "\n",
    "The sensors fitted across different machines involved in the process of energy generation collect data related to various environmental factors (temperature, humidity, wind speed, etc.) and additional features related to various parts of the wind turbine (gearbox, tower, blades, break, etc.). \n",
    "\n",
    "\n",
    "\n",
    "## Objective\n",
    "“ReneWind” is a company working on improving the machinery/processes involved in the production of wind energy using machine learning and has collected data of generator failure of wind turbines using sensors. They have shared a ciphered version of the data, as the data collected through sensors is confidential (the type of data collected varies with companies). Data has 40 predictors, 20000 observations in the training set and 5000 in the test set.\n",
    "\n",
    "The objective is to build various classification models, tune them, and find the best one that will help identify failures so that the generators could be repaired before failing/breaking to reduce the overall maintenance cost. \n",
    "The nature of predictions made by the classification model will translate as follows:\n",
    "\n",
    "- True positives (TP) are failures correctly predicted by the model. These will result in repairing costs.\n",
    "- False negatives (FN) are real failures where there is no detection by the model. These will result in replacement costs.\n",
    "- False positives (FP) are detections where there is no failure. These will result in inspection costs.\n",
    "\n",
    "It is given that the cost of repairing a generator is much less than the cost of replacing it, and the cost of inspection is less than the cost of repair.\n",
    "\n",
    "“1” in the target variables should be considered as “failure” and “0” represents “No failure”.\n",
    "\n",
    "## Data Description\n",
    "- The data provided is a transformed version of original data which was collected using sensors.\n",
    "- Train.csv - To be used for training and tuning of models. \n",
    "- Test.csv - To be used only for testing the performance of the final best model.\n",
    "- Both the datasets consist of 40 predictor variables and 1 target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_-uuGqH-qTt"
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "83D17_Wl4jal"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# To suppress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores, and split data\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n)\\nfrom sklearn import metrics\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To do hyperparameter tuning\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\npd.set_option(\\\"display.max_rows\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\";\n",
       "                var nbb_formatted_code = \"# This will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n\\n# To suppress warnings\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# Libraries to help with reading and manipulating data\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libaries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# To tune model, get different metric scores, and split data\\nfrom sklearn.metrics import (\\n    f1_score,\\n    accuracy_score,\\n    recall_score,\\n    precision_score,\\n    confusion_matrix,\\n    roc_auc_score,\\n    plot_confusion_matrix,\\n)\\nfrom sklearn import metrics\\n\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\\n\\n# To be used for data scaling and one hot encoding\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\\n\\n# To impute missing values\\nfrom sklearn.impute import SimpleImputer\\n\\n# To oversample and undersample data\\nfrom imblearn.over_sampling import SMOTE\\nfrom imblearn.under_sampling import RandomUnderSampler\\n\\n# To do hyperparameter tuning\\nfrom sklearn.model_selection import RandomizedSearchCV\\n\\n# To be used for creating pipelines and personalizing them\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.compose import ColumnTransformer\\n\\n# To define maximum number of columns to be displayed in a dataframe\\npd.set_option(\\\"display.max_columns\\\", None)\\npd.set_option(\\\"display.max_rows\\\", None)\\n\\n# To supress scientific notations for a dataframe\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\\n\\n# To help with model building\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.ensemble import (\\n    AdaBoostClassifier,\\n    GradientBoostingClassifier,\\n    RandomForestClassifier,\\n    BaggingClassifier,\\n)\\nfrom xgboost import XGBClassifier\\n\\n# To suppress scientific notations\\npd.set_option(\\\"display.float_format\\\", lambda x: \\\"%.3f\\\" % x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black\n",
    "\n",
    "# To suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Libraries to help with reading and manipulating data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libaries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To tune model, get different metric scores, and split data\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# To be used for data scaling and one hot encoding\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# To impute missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# To oversample and undersample data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# To do hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# To be used for creating pipelines and personalizing them\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# To define maximum number of columns to be displayed in a dataframe\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# To supress scientific notations for a dataframe\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)\n",
    "\n",
    "# To help with model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# To suppress scientific notations\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxhpZv9y-qTw"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oJnKoHy14jam"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"df_train = pd.read_csv(\\n    \\\"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Train.csv\\\"\\n)\\ndf_test = pd.read_csv(\\\"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Test.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df_train = pd.read_csv(\\n    \\\"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Train.csv\\\"\\n)\\ndf_test = pd.read_csv(\\\"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Test.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Train.csv\"\n",
    ")\n",
    "df_test = pd.read_csv(\"C:/Users/mctal/Documents/DSBA materials/6 Model Tuning/Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvpMDcaaMKtI"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIiCRwqZ54_C"
   },
   "source": [
    "- Observations\n",
    "- Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "01hJQ7EfMKtK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.465</td>\n",
       "      <td>-4.679</td>\n",
       "      <td>3.102</td>\n",
       "      <td>0.506</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-2.033</td>\n",
       "      <td>-2.911</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-1.522</td>\n",
       "      <td>3.762</td>\n",
       "      <td>-5.715</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.418</td>\n",
       "      <td>-3.376</td>\n",
       "      <td>-3.047</td>\n",
       "      <td>0.306</td>\n",
       "      <td>2.914</td>\n",
       "      <td>2.270</td>\n",
       "      <td>4.395</td>\n",
       "      <td>-2.388</td>\n",
       "      <td>0.646</td>\n",
       "      <td>-1.191</td>\n",
       "      <td>3.133</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-2.511</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.726</td>\n",
       "      <td>-3.982</td>\n",
       "      <td>-1.073</td>\n",
       "      <td>1.667</td>\n",
       "      <td>3.060</td>\n",
       "      <td>-1.690</td>\n",
       "      <td>2.846</td>\n",
       "      <td>2.235</td>\n",
       "      <td>6.667</td>\n",
       "      <td>0.444</td>\n",
       "      <td>-2.369</td>\n",
       "      <td>2.951</td>\n",
       "      <td>-3.480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.366</td>\n",
       "      <td>3.653</td>\n",
       "      <td>0.910</td>\n",
       "      <td>-1.368</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2.359</td>\n",
       "      <td>0.733</td>\n",
       "      <td>-4.332</td>\n",
       "      <td>0.566</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>1.914</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>-1.255</td>\n",
       "      <td>-2.707</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-4.769</td>\n",
       "      <td>-2.205</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.757</td>\n",
       "      <td>-5.834</td>\n",
       "      <td>-3.065</td>\n",
       "      <td>1.597</td>\n",
       "      <td>-1.757</td>\n",
       "      <td>1.766</td>\n",
       "      <td>-0.267</td>\n",
       "      <td>3.625</td>\n",
       "      <td>1.500</td>\n",
       "      <td>-0.586</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-1.795</td>\n",
       "      <td>3.033</td>\n",
       "      <td>-2.468</td>\n",
       "      <td>1.895</td>\n",
       "      <td>-2.298</td>\n",
       "      <td>-1.731</td>\n",
       "      <td>5.909</td>\n",
       "      <td>-0.386</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.832</td>\n",
       "      <td>-5.824</td>\n",
       "      <td>0.634</td>\n",
       "      <td>-2.419</td>\n",
       "      <td>-1.774</td>\n",
       "      <td>1.017</td>\n",
       "      <td>-2.099</td>\n",
       "      <td>-3.173</td>\n",
       "      <td>-2.082</td>\n",
       "      <td>5.393</td>\n",
       "      <td>-0.771</td>\n",
       "      <td>1.107</td>\n",
       "      <td>1.144</td>\n",
       "      <td>0.943</td>\n",
       "      <td>-3.164</td>\n",
       "      <td>-4.248</td>\n",
       "      <td>-4.039</td>\n",
       "      <td>3.689</td>\n",
       "      <td>3.311</td>\n",
       "      <td>1.059</td>\n",
       "      <td>-2.143</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-1.661</td>\n",
       "      <td>1.680</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-4.551</td>\n",
       "      <td>3.739</td>\n",
       "      <td>1.134</td>\n",
       "      <td>-2.034</td>\n",
       "      <td>0.841</td>\n",
       "      <td>-1.600</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.804</td>\n",
       "      <td>4.086</td>\n",
       "      <td>2.292</td>\n",
       "      <td>5.361</td>\n",
       "      <td>0.352</td>\n",
       "      <td>2.940</td>\n",
       "      <td>3.839</td>\n",
       "      <td>-4.309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.618</td>\n",
       "      <td>1.888</td>\n",
       "      <td>7.046</td>\n",
       "      <td>-1.147</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-1.530</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-2.494</td>\n",
       "      <td>0.345</td>\n",
       "      <td>2.119</td>\n",
       "      <td>-3.053</td>\n",
       "      <td>0.460</td>\n",
       "      <td>2.705</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>-3.174</td>\n",
       "      <td>-3.404</td>\n",
       "      <td>-1.282</td>\n",
       "      <td>1.582</td>\n",
       "      <td>-1.952</td>\n",
       "      <td>-3.517</td>\n",
       "      <td>-1.206</td>\n",
       "      <td>-5.628</td>\n",
       "      <td>-1.818</td>\n",
       "      <td>2.124</td>\n",
       "      <td>5.295</td>\n",
       "      <td>4.748</td>\n",
       "      <td>-2.309</td>\n",
       "      <td>-3.963</td>\n",
       "      <td>-6.029</td>\n",
       "      <td>4.949</td>\n",
       "      <td>-3.584</td>\n",
       "      <td>-2.577</td>\n",
       "      <td>1.364</td>\n",
       "      <td>0.623</td>\n",
       "      <td>5.550</td>\n",
       "      <td>-1.527</td>\n",
       "      <td>0.139</td>\n",
       "      <td>3.101</td>\n",
       "      <td>-1.277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.111</td>\n",
       "      <td>3.872</td>\n",
       "      <td>-3.758</td>\n",
       "      <td>-2.983</td>\n",
       "      <td>3.793</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.205</td>\n",
       "      <td>4.849</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-6.220</td>\n",
       "      <td>1.998</td>\n",
       "      <td>4.724</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-1.989</td>\n",
       "      <td>-2.633</td>\n",
       "      <td>4.184</td>\n",
       "      <td>2.245</td>\n",
       "      <td>3.734</td>\n",
       "      <td>-6.313</td>\n",
       "      <td>-5.380</td>\n",
       "      <td>-0.887</td>\n",
       "      <td>2.062</td>\n",
       "      <td>9.446</td>\n",
       "      <td>4.490</td>\n",
       "      <td>-3.945</td>\n",
       "      <td>4.582</td>\n",
       "      <td>-8.780</td>\n",
       "      <td>-3.383</td>\n",
       "      <td>5.107</td>\n",
       "      <td>6.788</td>\n",
       "      <td>2.044</td>\n",
       "      <td>8.266</td>\n",
       "      <td>6.629</td>\n",
       "      <td>-10.069</td>\n",
       "      <td>1.223</td>\n",
       "      <td>-3.230</td>\n",
       "      <td>1.687</td>\n",
       "      <td>-2.164</td>\n",
       "      <td>-3.645</td>\n",
       "      <td>6.510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1     V2     V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
       "0 -4.465 -4.679  3.102  0.506 -0.221 -2.033 -2.911  0.051 -1.522  3.762   \n",
       "1  3.366  3.653  0.910 -1.368  0.332  2.359  0.733 -4.332  0.566 -0.101   \n",
       "2 -3.832 -5.824  0.634 -2.419 -1.774  1.017 -2.099 -3.173 -2.082  5.393   \n",
       "3  1.618  1.888  7.046 -1.147  0.083 -1.530  0.207 -2.494  0.345  2.119   \n",
       "4 -0.111  3.872 -3.758 -2.983  3.793  0.545  0.205  4.849 -1.855 -6.220   \n",
       "\n",
       "     V11    V12    V13    V14    V15    V16    V17    V18    V19    V20  \\\n",
       "0 -5.715  0.736  0.981  1.418 -3.376 -3.047  0.306  2.914  2.270  4.395   \n",
       "1  1.914 -0.951 -1.255 -2.707  0.193 -4.769 -2.205  0.908  0.757 -5.834   \n",
       "2 -0.771  1.107  1.144  0.943 -3.164 -4.248 -4.039  3.689  3.311  1.059   \n",
       "3 -3.053  0.460  2.705 -0.636 -0.454 -3.174 -3.404 -1.282  1.582 -1.952   \n",
       "4  1.998  4.724  0.709 -1.989 -2.633  4.184  2.245  3.734 -6.313 -5.380   \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28    V29    V30  \\\n",
       "0 -2.388  0.646 -1.191  3.133  0.665 -2.511 -0.037  0.726 -3.982 -1.073   \n",
       "1 -3.065  1.597 -1.757  1.766 -0.267  3.625  1.500 -0.586  0.783 -0.201   \n",
       "2 -2.143  1.650 -1.661  1.680 -0.451 -4.551  3.739  1.134 -2.034  0.841   \n",
       "3 -3.517 -1.206 -5.628 -1.818  2.124  5.295  4.748 -2.309 -3.963 -6.029   \n",
       "4 -0.887  2.062  9.446  4.490 -3.945  4.582 -8.780 -3.383  5.107  6.788   \n",
       "\n",
       "     V31    V32    V33     V34   V35    V36    V37    V38    V39    V40  \\\n",
       "0  1.667  3.060 -1.690   2.846 2.235  6.667  0.444 -2.369  2.951 -3.480   \n",
       "1  0.025 -1.795  3.033  -2.468 1.895 -2.298 -1.731  5.909 -0.386  0.616   \n",
       "2 -1.600 -0.257  0.804   4.086 2.292  5.361  0.352  2.940  3.839 -4.309   \n",
       "3  4.949 -3.584 -2.577   1.364 0.623  5.550 -1.527  0.139  3.101 -1.277   \n",
       "4  2.044  8.266  6.629 -10.069 1.223 -3.230  1.687 -2.164 -3.645  6.510   \n",
       "\n",
       "   Target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"df_train.head()\";\n",
       "                var nbb_formatted_code = \"df_train.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train dataset loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>V38</th>\n",
       "      <th>V39</th>\n",
       "      <th>V40</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.613</td>\n",
       "      <td>-3.820</td>\n",
       "      <td>2.202</td>\n",
       "      <td>1.300</td>\n",
       "      <td>-1.185</td>\n",
       "      <td>-4.496</td>\n",
       "      <td>-1.836</td>\n",
       "      <td>4.723</td>\n",
       "      <td>1.206</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-5.123</td>\n",
       "      <td>1.017</td>\n",
       "      <td>4.819</td>\n",
       "      <td>3.269</td>\n",
       "      <td>-2.984</td>\n",
       "      <td>1.387</td>\n",
       "      <td>2.032</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>-1.023</td>\n",
       "      <td>7.339</td>\n",
       "      <td>-2.242</td>\n",
       "      <td>0.155</td>\n",
       "      <td>2.054</td>\n",
       "      <td>-2.772</td>\n",
       "      <td>1.851</td>\n",
       "      <td>-1.789</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-1.255</td>\n",
       "      <td>-3.833</td>\n",
       "      <td>-1.505</td>\n",
       "      <td>1.587</td>\n",
       "      <td>2.291</td>\n",
       "      <td>-5.411</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.574</td>\n",
       "      <td>4.157</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-10.511</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-1.448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390</td>\n",
       "      <td>-0.512</td>\n",
       "      <td>0.527</td>\n",
       "      <td>-2.577</td>\n",
       "      <td>-1.017</td>\n",
       "      <td>2.235</td>\n",
       "      <td>-0.441</td>\n",
       "      <td>-4.406</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>1.967</td>\n",
       "      <td>1.797</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.638</td>\n",
       "      <td>-1.390</td>\n",
       "      <td>-1.883</td>\n",
       "      <td>-5.018</td>\n",
       "      <td>-3.827</td>\n",
       "      <td>2.418</td>\n",
       "      <td>1.762</td>\n",
       "      <td>-3.242</td>\n",
       "      <td>-3.193</td>\n",
       "      <td>1.857</td>\n",
       "      <td>-1.708</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.588</td>\n",
       "      <td>0.084</td>\n",
       "      <td>3.014</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.865</td>\n",
       "      <td>-1.782</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>2.494</td>\n",
       "      <td>0.315</td>\n",
       "      <td>2.059</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>5.128</td>\n",
       "      <td>1.721</td>\n",
       "      <td>-1.488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.875</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>4.084</td>\n",
       "      <td>-1.590</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-1.958</td>\n",
       "      <td>-0.695</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-1.732</td>\n",
       "      <td>0.466</td>\n",
       "      <td>-4.928</td>\n",
       "      <td>3.565</td>\n",
       "      <td>-0.449</td>\n",
       "      <td>-0.656</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-1.630</td>\n",
       "      <td>2.292</td>\n",
       "      <td>2.396</td>\n",
       "      <td>0.601</td>\n",
       "      <td>1.794</td>\n",
       "      <td>-2.120</td>\n",
       "      <td>0.482</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>1.790</td>\n",
       "      <td>1.874</td>\n",
       "      <td>0.364</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-2.119</td>\n",
       "      <td>-2.157</td>\n",
       "      <td>2.907</td>\n",
       "      <td>-1.319</td>\n",
       "      <td>-2.997</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.620</td>\n",
       "      <td>5.632</td>\n",
       "      <td>1.324</td>\n",
       "      <td>-1.752</td>\n",
       "      <td>1.808</td>\n",
       "      <td>1.676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.238</td>\n",
       "      <td>1.459</td>\n",
       "      <td>4.015</td>\n",
       "      <td>2.534</td>\n",
       "      <td>1.197</td>\n",
       "      <td>-3.117</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.322</td>\n",
       "      <td>0.702</td>\n",
       "      <td>-5.578</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>2.591</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-2.391</td>\n",
       "      <td>-2.342</td>\n",
       "      <td>0.572</td>\n",
       "      <td>-0.934</td>\n",
       "      <td>0.509</td>\n",
       "      <td>1.211</td>\n",
       "      <td>-3.260</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>1.498</td>\n",
       "      <td>1.100</td>\n",
       "      <td>4.143</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>-1.137</td>\n",
       "      <td>-5.356</td>\n",
       "      <td>-4.546</td>\n",
       "      <td>3.809</td>\n",
       "      <td>3.518</td>\n",
       "      <td>-3.074</td>\n",
       "      <td>-0.284</td>\n",
       "      <td>0.955</td>\n",
       "      <td>3.029</td>\n",
       "      <td>-1.367</td>\n",
       "      <td>-3.412</td>\n",
       "      <td>0.906</td>\n",
       "      <td>-2.451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.828</td>\n",
       "      <td>2.768</td>\n",
       "      <td>-1.235</td>\n",
       "      <td>2.809</td>\n",
       "      <td>-1.642</td>\n",
       "      <td>-1.407</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.965</td>\n",
       "      <td>1.918</td>\n",
       "      <td>-2.775</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>1.375</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>-1.679</td>\n",
       "      <td>-0.379</td>\n",
       "      <td>-4.443</td>\n",
       "      <td>3.894</td>\n",
       "      <td>-0.608</td>\n",
       "      <td>2.945</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-5.789</td>\n",
       "      <td>4.598</td>\n",
       "      <td>4.450</td>\n",
       "      <td>3.225</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-2.362</td>\n",
       "      <td>1.079</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>2.243</td>\n",
       "      <td>-3.591</td>\n",
       "      <td>1.774</td>\n",
       "      <td>-1.502</td>\n",
       "      <td>-2.227</td>\n",
       "      <td>4.777</td>\n",
       "      <td>-6.560</td>\n",
       "      <td>-0.806</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-3.858</td>\n",
       "      <td>-0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      V1     V2     V3     V4     V5     V6     V7     V8     V9    V10  \\\n",
       "0 -0.613 -3.820  2.202  1.300 -1.185 -4.496 -1.836  4.723  1.206 -0.342   \n",
       "1  0.390 -0.512  0.527 -2.577 -1.017  2.235 -0.441 -4.406 -0.333  1.967   \n",
       "2 -0.875 -0.641  4.084 -1.590  0.526 -1.958 -0.695  1.347 -1.732  0.466   \n",
       "3  0.238  1.459  4.015  2.534  1.197 -3.117 -0.924  0.269  1.322  0.702   \n",
       "4  5.828  2.768 -1.235  2.809 -1.642 -1.407  0.569  0.965  1.918 -2.775   \n",
       "\n",
       "     V11    V12    V13    V14    V15    V16    V17    V18    V19    V20  \\\n",
       "0 -5.123  1.017  4.819  3.269 -2.984  1.387  2.032 -0.512 -1.023  7.339   \n",
       "1  1.797  0.410  0.638 -1.390 -1.883 -5.018 -3.827  2.418  1.762 -3.242   \n",
       "2 -4.928  3.565 -0.449 -0.656 -0.167 -1.630  2.292  2.396  0.601  1.794   \n",
       "3 -5.578 -0.851  2.591  0.767 -2.391 -2.342  0.572 -0.934  0.509  1.211   \n",
       "4 -0.530  1.375 -0.651 -1.679 -0.379 -4.443  3.894 -0.608  2.945  0.367   \n",
       "\n",
       "     V21   V22    V23    V24    V25    V26    V27    V28    V29    V30    V31  \\\n",
       "0 -2.242 0.155  2.054 -2.772  1.851 -1.789 -0.277 -1.255 -3.833 -1.505  1.587   \n",
       "1 -3.193 1.857 -1.708  0.633 -0.588  0.084  3.014 -0.182  0.224  0.865 -1.782   \n",
       "2 -2.120 0.482 -0.841  1.790  1.874  0.364 -0.169 -0.484 -2.119 -2.157  2.907   \n",
       "3 -3.260 0.105 -0.659  1.498  1.100  4.143 -0.248 -1.137 -5.356 -4.546  3.809   \n",
       "4 -5.789 4.598  4.450  3.225  0.397  0.248 -2.362  1.079 -0.473  2.243 -3.591   \n",
       "\n",
       "     V32    V33    V34   V35    V36    V37     V38    V39    V40  Target  \n",
       "0  2.291 -5.411  0.870 0.574  4.157  1.428 -10.511  0.455 -1.448       0  \n",
       "1 -2.475  2.494  0.315 2.059  0.684 -0.485   5.128  1.721 -1.488       0  \n",
       "2 -1.319 -2.997  0.460 0.620  5.632  1.324  -1.752  1.808  1.676       0  \n",
       "3  3.518 -3.074 -0.284 0.955  3.029 -1.367  -3.412  0.906 -2.451       0  \n",
       "4  1.774 -1.502 -2.227 4.777 -6.560 -0.806  -0.276 -3.858 -0.538       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"df_test.head()\";\n",
       "                var nbb_formatted_code = \"df_test.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test dataset loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"df_train.shape\";\n",
       "                var nbb_formatted_code = \"df_train.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 20,000 rows and 41 columns in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 41)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"df_test.shape\";\n",
       "                var nbb_formatted_code = \"df_test.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 5,000 rows and 41 columns in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 41 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      19982 non-null  float64\n",
      " 1   V2      19982 non-null  float64\n",
      " 2   V3      20000 non-null  float64\n",
      " 3   V4      20000 non-null  float64\n",
      " 4   V5      20000 non-null  float64\n",
      " 5   V6      20000 non-null  float64\n",
      " 6   V7      20000 non-null  float64\n",
      " 7   V8      20000 non-null  float64\n",
      " 8   V9      20000 non-null  float64\n",
      " 9   V10     20000 non-null  float64\n",
      " 10  V11     20000 non-null  float64\n",
      " 11  V12     20000 non-null  float64\n",
      " 12  V13     20000 non-null  float64\n",
      " 13  V14     20000 non-null  float64\n",
      " 14  V15     20000 non-null  float64\n",
      " 15  V16     20000 non-null  float64\n",
      " 16  V17     20000 non-null  float64\n",
      " 17  V18     20000 non-null  float64\n",
      " 18  V19     20000 non-null  float64\n",
      " 19  V20     20000 non-null  float64\n",
      " 20  V21     20000 non-null  float64\n",
      " 21  V22     20000 non-null  float64\n",
      " 22  V23     20000 non-null  float64\n",
      " 23  V24     20000 non-null  float64\n",
      " 24  V25     20000 non-null  float64\n",
      " 25  V26     20000 non-null  float64\n",
      " 26  V27     20000 non-null  float64\n",
      " 27  V28     20000 non-null  float64\n",
      " 28  V29     20000 non-null  float64\n",
      " 29  V30     20000 non-null  float64\n",
      " 30  V31     20000 non-null  float64\n",
      " 31  V32     20000 non-null  float64\n",
      " 32  V33     20000 non-null  float64\n",
      " 33  V34     20000 non-null  float64\n",
      " 34  V35     20000 non-null  float64\n",
      " 35  V36     20000 non-null  float64\n",
      " 36  V37     20000 non-null  float64\n",
      " 37  V38     20000 non-null  float64\n",
      " 38  V39     20000 non-null  float64\n",
      " 39  V40     20000 non-null  float64\n",
      " 40  Target  20000 non-null  int64  \n",
      "dtypes: float64(40), int64(1)\n",
      "memory usage: 6.3 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"df_train.info()\";\n",
       "                var nbb_formatted_code = \"df_train.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All columns are of numerical values\n",
    "- There are some missing values in columns V1 and V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 41 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   V1      4995 non-null   float64\n",
      " 1   V2      4994 non-null   float64\n",
      " 2   V3      5000 non-null   float64\n",
      " 3   V4      5000 non-null   float64\n",
      " 4   V5      5000 non-null   float64\n",
      " 5   V6      5000 non-null   float64\n",
      " 6   V7      5000 non-null   float64\n",
      " 7   V8      5000 non-null   float64\n",
      " 8   V9      5000 non-null   float64\n",
      " 9   V10     5000 non-null   float64\n",
      " 10  V11     5000 non-null   float64\n",
      " 11  V12     5000 non-null   float64\n",
      " 12  V13     5000 non-null   float64\n",
      " 13  V14     5000 non-null   float64\n",
      " 14  V15     5000 non-null   float64\n",
      " 15  V16     5000 non-null   float64\n",
      " 16  V17     5000 non-null   float64\n",
      " 17  V18     5000 non-null   float64\n",
      " 18  V19     5000 non-null   float64\n",
      " 19  V20     5000 non-null   float64\n",
      " 20  V21     5000 non-null   float64\n",
      " 21  V22     5000 non-null   float64\n",
      " 22  V23     5000 non-null   float64\n",
      " 23  V24     5000 non-null   float64\n",
      " 24  V25     5000 non-null   float64\n",
      " 25  V26     5000 non-null   float64\n",
      " 26  V27     5000 non-null   float64\n",
      " 27  V28     5000 non-null   float64\n",
      " 28  V29     5000 non-null   float64\n",
      " 29  V30     5000 non-null   float64\n",
      " 30  V31     5000 non-null   float64\n",
      " 31  V32     5000 non-null   float64\n",
      " 32  V33     5000 non-null   float64\n",
      " 33  V34     5000 non-null   float64\n",
      " 34  V35     5000 non-null   float64\n",
      " 35  V36     5000 non-null   float64\n",
      " 36  V37     5000 non-null   float64\n",
      " 37  V38     5000 non-null   float64\n",
      " 38  V39     5000 non-null   float64\n",
      " 39  V40     5000 non-null   float64\n",
      " 40  Target  5000 non-null   int64  \n",
      "dtypes: float64(40), int64(1)\n",
      "memory usage: 1.6 MB\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"df_test.info()\";\n",
       "                var nbb_formatted_code = \"df_test.info()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All columns are of numerical values\n",
    "- There are some missing values in columns V1 and V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"df_train.duplicated().sum()\";\n",
       "                var nbb_formatted_code = \"df_train.duplicated().sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no duplicated values in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"df_test.duplicated().sum()\";\n",
       "                var nbb_formatted_code = \"df_test.duplicated().sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no duplicated values in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        18\n",
       "V2        18\n",
       "V3         0\n",
       "V4         0\n",
       "V5         0\n",
       "V6         0\n",
       "V7         0\n",
       "V8         0\n",
       "V9         0\n",
       "V10        0\n",
       "V11        0\n",
       "V12        0\n",
       "V13        0\n",
       "V14        0\n",
       "V15        0\n",
       "V16        0\n",
       "V17        0\n",
       "V18        0\n",
       "V19        0\n",
       "V20        0\n",
       "V21        0\n",
       "V22        0\n",
       "V23        0\n",
       "V24        0\n",
       "V25        0\n",
       "V26        0\n",
       "V27        0\n",
       "V28        0\n",
       "V29        0\n",
       "V30        0\n",
       "V31        0\n",
       "V32        0\n",
       "V33        0\n",
       "V34        0\n",
       "V35        0\n",
       "V36        0\n",
       "V37        0\n",
       "V38        0\n",
       "V39        0\n",
       "V40        0\n",
       "Target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"df_train.isnull().sum()\";\n",
       "                var nbb_formatted_code = \"df_train.isnull().sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There 18 missing values in columns V1 and V2 respectively in train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        5\n",
       "V2        6\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "V29       0\n",
       "V30       0\n",
       "V31       0\n",
       "V32       0\n",
       "V33       0\n",
       "V34       0\n",
       "V35       0\n",
       "V36       0\n",
       "V37       0\n",
       "V38       0\n",
       "V39       0\n",
       "V40       0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"df_test.isnull().sum()\";\n",
       "                var nbb_formatted_code = \"df_test.isnull().sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There 5 and 6 missing values in columns V1 and V2 respectively in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>19982.000</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>3.442</td>\n",
       "      <td>-11.876</td>\n",
       "      <td>-2.737</td>\n",
       "      <td>-0.748</td>\n",
       "      <td>1.840</td>\n",
       "      <td>15.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>19982.000</td>\n",
       "      <td>0.440</td>\n",
       "      <td>3.151</td>\n",
       "      <td>-12.320</td>\n",
       "      <td>-1.641</td>\n",
       "      <td>0.472</td>\n",
       "      <td>2.544</td>\n",
       "      <td>13.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>2.485</td>\n",
       "      <td>3.389</td>\n",
       "      <td>-10.708</td>\n",
       "      <td>0.207</td>\n",
       "      <td>2.256</td>\n",
       "      <td>4.566</td>\n",
       "      <td>17.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>3.432</td>\n",
       "      <td>-15.082</td>\n",
       "      <td>-2.348</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>2.131</td>\n",
       "      <td>13.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>2.105</td>\n",
       "      <td>-8.603</td>\n",
       "      <td>-1.536</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>1.340</td>\n",
       "      <td>8.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>2.041</td>\n",
       "      <td>-10.227</td>\n",
       "      <td>-2.347</td>\n",
       "      <td>-1.001</td>\n",
       "      <td>0.380</td>\n",
       "      <td>6.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.879</td>\n",
       "      <td>1.762</td>\n",
       "      <td>-7.950</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>0.224</td>\n",
       "      <td>8.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.548</td>\n",
       "      <td>3.296</td>\n",
       "      <td>-15.658</td>\n",
       "      <td>-2.643</td>\n",
       "      <td>-0.389</td>\n",
       "      <td>1.723</td>\n",
       "      <td>11.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>2.161</td>\n",
       "      <td>-8.596</td>\n",
       "      <td>-1.495</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>1.409</td>\n",
       "      <td>8.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>2.193</td>\n",
       "      <td>-9.854</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1.477</td>\n",
       "      <td>8.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-1.895</td>\n",
       "      <td>3.124</td>\n",
       "      <td>-14.832</td>\n",
       "      <td>-3.922</td>\n",
       "      <td>-1.921</td>\n",
       "      <td>0.119</td>\n",
       "      <td>11.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.605</td>\n",
       "      <td>2.930</td>\n",
       "      <td>-12.948</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>1.508</td>\n",
       "      <td>3.571</td>\n",
       "      <td>15.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.580</td>\n",
       "      <td>2.875</td>\n",
       "      <td>-13.228</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.637</td>\n",
       "      <td>3.460</td>\n",
       "      <td>15.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.951</td>\n",
       "      <td>1.790</td>\n",
       "      <td>-7.739</td>\n",
       "      <td>-2.171</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>0.271</td>\n",
       "      <td>5.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-2.415</td>\n",
       "      <td>3.355</td>\n",
       "      <td>-16.417</td>\n",
       "      <td>-4.415</td>\n",
       "      <td>-2.383</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>12.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-2.925</td>\n",
       "      <td>4.222</td>\n",
       "      <td>-20.374</td>\n",
       "      <td>-5.634</td>\n",
       "      <td>-2.683</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>13.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>3.345</td>\n",
       "      <td>-14.091</td>\n",
       "      <td>-2.216</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>2.069</td>\n",
       "      <td>16.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.189</td>\n",
       "      <td>2.592</td>\n",
       "      <td>-11.644</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.883</td>\n",
       "      <td>2.572</td>\n",
       "      <td>13.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.182</td>\n",
       "      <td>3.397</td>\n",
       "      <td>-13.492</td>\n",
       "      <td>-1.050</td>\n",
       "      <td>1.279</td>\n",
       "      <td>3.493</td>\n",
       "      <td>13.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>3.669</td>\n",
       "      <td>-13.923</td>\n",
       "      <td>-2.433</td>\n",
       "      <td>0.033</td>\n",
       "      <td>2.512</td>\n",
       "      <td>16.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-3.611</td>\n",
       "      <td>3.568</td>\n",
       "      <td>-17.956</td>\n",
       "      <td>-5.930</td>\n",
       "      <td>-3.533</td>\n",
       "      <td>-1.266</td>\n",
       "      <td>13.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>1.652</td>\n",
       "      <td>-10.122</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.975</td>\n",
       "      <td>2.026</td>\n",
       "      <td>7.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>4.032</td>\n",
       "      <td>-14.866</td>\n",
       "      <td>-3.099</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>2.452</td>\n",
       "      <td>14.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.134</td>\n",
       "      <td>3.912</td>\n",
       "      <td>-16.387</td>\n",
       "      <td>-1.468</td>\n",
       "      <td>0.969</td>\n",
       "      <td>3.546</td>\n",
       "      <td>17.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.017</td>\n",
       "      <td>-8.228</td>\n",
       "      <td>-1.365</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.397</td>\n",
       "      <td>8.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.874</td>\n",
       "      <td>3.435</td>\n",
       "      <td>-11.834</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>1.951</td>\n",
       "      <td>4.130</td>\n",
       "      <td>16.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>4.369</td>\n",
       "      <td>-14.905</td>\n",
       "      <td>-3.652</td>\n",
       "      <td>-0.885</td>\n",
       "      <td>2.189</td>\n",
       "      <td>17.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.883</td>\n",
       "      <td>1.918</td>\n",
       "      <td>-9.269</td>\n",
       "      <td>-2.171</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>0.376</td>\n",
       "      <td>6.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>2.684</td>\n",
       "      <td>-12.579</td>\n",
       "      <td>-2.787</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.630</td>\n",
       "      <td>10.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>3.005</td>\n",
       "      <td>-14.796</td>\n",
       "      <td>-1.867</td>\n",
       "      <td>0.184</td>\n",
       "      <td>2.036</td>\n",
       "      <td>12.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V31</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.487</td>\n",
       "      <td>3.461</td>\n",
       "      <td>-13.723</td>\n",
       "      <td>-1.818</td>\n",
       "      <td>0.490</td>\n",
       "      <td>2.731</td>\n",
       "      <td>17.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V32</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.304</td>\n",
       "      <td>5.500</td>\n",
       "      <td>-19.877</td>\n",
       "      <td>-3.420</td>\n",
       "      <td>0.052</td>\n",
       "      <td>3.762</td>\n",
       "      <td>23.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V33</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>3.575</td>\n",
       "      <td>-16.898</td>\n",
       "      <td>-2.243</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>2.255</td>\n",
       "      <td>16.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V34</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>3.184</td>\n",
       "      <td>-17.985</td>\n",
       "      <td>-2.137</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>1.437</td>\n",
       "      <td>14.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V35</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>2.230</td>\n",
       "      <td>2.937</td>\n",
       "      <td>-15.350</td>\n",
       "      <td>0.336</td>\n",
       "      <td>2.099</td>\n",
       "      <td>4.064</td>\n",
       "      <td>15.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V36</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>1.515</td>\n",
       "      <td>3.801</td>\n",
       "      <td>-14.833</td>\n",
       "      <td>-0.944</td>\n",
       "      <td>1.567</td>\n",
       "      <td>3.984</td>\n",
       "      <td>19.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V37</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.788</td>\n",
       "      <td>-5.478</td>\n",
       "      <td>-1.256</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>1.176</td>\n",
       "      <td>7.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V38</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>3.948</td>\n",
       "      <td>-17.375</td>\n",
       "      <td>-2.988</td>\n",
       "      <td>-0.317</td>\n",
       "      <td>2.279</td>\n",
       "      <td>15.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V39</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.753</td>\n",
       "      <td>-6.439</td>\n",
       "      <td>-0.272</td>\n",
       "      <td>0.919</td>\n",
       "      <td>2.058</td>\n",
       "      <td>7.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V40</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>3.012</td>\n",
       "      <td>-11.024</td>\n",
       "      <td>-2.940</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>1.120</td>\n",
       "      <td>10.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>20000.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count   mean   std     min    25%    50%    75%    max\n",
       "V1     19982.000 -0.272 3.442 -11.876 -2.737 -0.748  1.840 15.493\n",
       "V2     19982.000  0.440 3.151 -12.320 -1.641  0.472  2.544 13.089\n",
       "V3     20000.000  2.485 3.389 -10.708  0.207  2.256  4.566 17.091\n",
       "V4     20000.000 -0.083 3.432 -15.082 -2.348 -0.135  2.131 13.236\n",
       "V5     20000.000 -0.054 2.105  -8.603 -1.536 -0.102  1.340  8.134\n",
       "V6     20000.000 -0.995 2.041 -10.227 -2.347 -1.001  0.380  6.976\n",
       "V7     20000.000 -0.879 1.762  -7.950 -2.031 -0.917  0.224  8.006\n",
       "V8     20000.000 -0.548 3.296 -15.658 -2.643 -0.389  1.723 11.679\n",
       "V9     20000.000 -0.017 2.161  -8.596 -1.495 -0.068  1.409  8.138\n",
       "V10    20000.000 -0.013 2.193  -9.854 -1.411  0.101  1.477  8.108\n",
       "V11    20000.000 -1.895 3.124 -14.832 -3.922 -1.921  0.119 11.826\n",
       "V12    20000.000  1.605 2.930 -12.948 -0.397  1.508  3.571 15.081\n",
       "V13    20000.000  1.580 2.875 -13.228 -0.224  1.637  3.460 15.420\n",
       "V14    20000.000 -0.951 1.790  -7.739 -2.171 -0.957  0.271  5.671\n",
       "V15    20000.000 -2.415 3.355 -16.417 -4.415 -2.383 -0.359 12.246\n",
       "V16    20000.000 -2.925 4.222 -20.374 -5.634 -2.683 -0.095 13.583\n",
       "V17    20000.000 -0.134 3.345 -14.091 -2.216 -0.015  2.069 16.756\n",
       "V18    20000.000  1.189 2.592 -11.644 -0.404  0.883  2.572 13.180\n",
       "V19    20000.000  1.182 3.397 -13.492 -1.050  1.279  3.493 13.238\n",
       "V20    20000.000  0.024 3.669 -13.923 -2.433  0.033  2.512 16.052\n",
       "V21    20000.000 -3.611 3.568 -17.956 -5.930 -3.533 -1.266 13.840\n",
       "V22    20000.000  0.952 1.652 -10.122 -0.118  0.975  2.026  7.410\n",
       "V23    20000.000 -0.366 4.032 -14.866 -3.099 -0.262  2.452 14.459\n",
       "V24    20000.000  1.134 3.912 -16.387 -1.468  0.969  3.546 17.163\n",
       "V25    20000.000 -0.002 2.017  -8.228 -1.365  0.025  1.397  8.223\n",
       "V26    20000.000  1.874 3.435 -11.834 -0.338  1.951  4.130 16.836\n",
       "V27    20000.000 -0.612 4.369 -14.905 -3.652 -0.885  2.189 17.560\n",
       "V28    20000.000 -0.883 1.918  -9.269 -2.171 -0.891  0.376  6.528\n",
       "V29    20000.000 -0.986 2.684 -12.579 -2.787 -1.176  0.630 10.722\n",
       "V30    20000.000 -0.016 3.005 -14.796 -1.867  0.184  2.036 12.506\n",
       "V31    20000.000  0.487 3.461 -13.723 -1.818  0.490  2.731 17.255\n",
       "V32    20000.000  0.304 5.500 -19.877 -3.420  0.052  3.762 23.633\n",
       "V33    20000.000  0.050 3.575 -16.898 -2.243 -0.066  2.255 16.692\n",
       "V34    20000.000 -0.463 3.184 -17.985 -2.137 -0.255  1.437 14.358\n",
       "V35    20000.000  2.230 2.937 -15.350  0.336  2.099  4.064 15.291\n",
       "V36    20000.000  1.515 3.801 -14.833 -0.944  1.567  3.984 19.330\n",
       "V37    20000.000  0.011 1.788  -5.478 -1.256 -0.128  1.176  7.467\n",
       "V38    20000.000 -0.344 3.948 -17.375 -2.988 -0.317  2.279 15.290\n",
       "V39    20000.000  0.891 1.753  -6.439 -0.272  0.919  2.058  7.760\n",
       "V40    20000.000 -0.876 3.012 -11.024 -2.940 -0.921  1.120 10.654\n",
       "Target 20000.000  0.056 0.229   0.000  0.000  0.000  0.000  1.000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"df_train.describe().T\";\n",
       "                var nbb_formatted_code = \"df_train.describe().T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- V1 to V40 columns have values ranging from negative to positive values\n",
    "- The columns will have a highly skewed distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>4995.000</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>3.466</td>\n",
       "      <td>-12.382</td>\n",
       "      <td>-2.744</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>1.831</td>\n",
       "      <td>13.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>4994.000</td>\n",
       "      <td>0.398</td>\n",
       "      <td>3.140</td>\n",
       "      <td>-10.716</td>\n",
       "      <td>-1.649</td>\n",
       "      <td>0.427</td>\n",
       "      <td>2.444</td>\n",
       "      <td>14.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>2.552</td>\n",
       "      <td>3.327</td>\n",
       "      <td>-9.238</td>\n",
       "      <td>0.315</td>\n",
       "      <td>2.260</td>\n",
       "      <td>4.587</td>\n",
       "      <td>15.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>3.414</td>\n",
       "      <td>-14.682</td>\n",
       "      <td>-2.293</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>2.166</td>\n",
       "      <td>12.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>2.111</td>\n",
       "      <td>-7.712</td>\n",
       "      <td>-1.615</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>1.341</td>\n",
       "      <td>7.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-1.042</td>\n",
       "      <td>2.005</td>\n",
       "      <td>-8.924</td>\n",
       "      <td>-2.369</td>\n",
       "      <td>-1.049</td>\n",
       "      <td>0.308</td>\n",
       "      <td>5.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.908</td>\n",
       "      <td>1.769</td>\n",
       "      <td>-8.124</td>\n",
       "      <td>-2.054</td>\n",
       "      <td>-0.940</td>\n",
       "      <td>0.212</td>\n",
       "      <td>7.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>3.332</td>\n",
       "      <td>-12.253</td>\n",
       "      <td>-2.642</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>1.713</td>\n",
       "      <td>10.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2.174</td>\n",
       "      <td>-6.785</td>\n",
       "      <td>-1.456</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>1.450</td>\n",
       "      <td>8.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>2.145</td>\n",
       "      <td>-8.171</td>\n",
       "      <td>-1.353</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.511</td>\n",
       "      <td>6.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-2.009</td>\n",
       "      <td>3.112</td>\n",
       "      <td>-13.152</td>\n",
       "      <td>-4.050</td>\n",
       "      <td>-2.043</td>\n",
       "      <td>0.044</td>\n",
       "      <td>9.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.576</td>\n",
       "      <td>2.907</td>\n",
       "      <td>-8.164</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>1.488</td>\n",
       "      <td>3.563</td>\n",
       "      <td>12.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.622</td>\n",
       "      <td>2.883</td>\n",
       "      <td>-11.548</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>1.719</td>\n",
       "      <td>3.465</td>\n",
       "      <td>12.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.921</td>\n",
       "      <td>1.803</td>\n",
       "      <td>-7.814</td>\n",
       "      <td>-2.111</td>\n",
       "      <td>-0.896</td>\n",
       "      <td>0.272</td>\n",
       "      <td>5.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-2.452</td>\n",
       "      <td>3.387</td>\n",
       "      <td>-15.286</td>\n",
       "      <td>-4.479</td>\n",
       "      <td>-2.417</td>\n",
       "      <td>-0.433</td>\n",
       "      <td>11.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-3.019</td>\n",
       "      <td>4.264</td>\n",
       "      <td>-20.986</td>\n",
       "      <td>-5.648</td>\n",
       "      <td>-2.774</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>13.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>3.337</td>\n",
       "      <td>-13.418</td>\n",
       "      <td>-2.228</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.112</td>\n",
       "      <td>19.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.196</td>\n",
       "      <td>2.586</td>\n",
       "      <td>-12.214</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>0.881</td>\n",
       "      <td>2.604</td>\n",
       "      <td>13.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.210</td>\n",
       "      <td>3.385</td>\n",
       "      <td>-14.170</td>\n",
       "      <td>-1.026</td>\n",
       "      <td>1.296</td>\n",
       "      <td>3.526</td>\n",
       "      <td>12.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>3.657</td>\n",
       "      <td>-13.720</td>\n",
       "      <td>-2.325</td>\n",
       "      <td>0.193</td>\n",
       "      <td>2.540</td>\n",
       "      <td>13.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-3.664</td>\n",
       "      <td>3.578</td>\n",
       "      <td>-16.341</td>\n",
       "      <td>-5.944</td>\n",
       "      <td>-3.663</td>\n",
       "      <td>-1.330</td>\n",
       "      <td>11.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1.640</td>\n",
       "      <td>-6.740</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.986</td>\n",
       "      <td>2.029</td>\n",
       "      <td>7.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>4.057</td>\n",
       "      <td>-14.422</td>\n",
       "      <td>-3.163</td>\n",
       "      <td>-0.279</td>\n",
       "      <td>2.426</td>\n",
       "      <td>13.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.089</td>\n",
       "      <td>3.968</td>\n",
       "      <td>-12.316</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.913</td>\n",
       "      <td>3.537</td>\n",
       "      <td>17.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.010</td>\n",
       "      <td>-6.770</td>\n",
       "      <td>-1.298</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1.428</td>\n",
       "      <td>6.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.847</td>\n",
       "      <td>3.400</td>\n",
       "      <td>-11.414</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>1.917</td>\n",
       "      <td>4.156</td>\n",
       "      <td>17.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>4.403</td>\n",
       "      <td>-13.177</td>\n",
       "      <td>-3.663</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>2.247</td>\n",
       "      <td>17.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>1.926</td>\n",
       "      <td>-7.933</td>\n",
       "      <td>-2.160</td>\n",
       "      <td>-0.931</td>\n",
       "      <td>0.421</td>\n",
       "      <td>7.416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V29</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-1.096</td>\n",
       "      <td>2.655</td>\n",
       "      <td>-9.988</td>\n",
       "      <td>-2.861</td>\n",
       "      <td>-1.341</td>\n",
       "      <td>0.522</td>\n",
       "      <td>14.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V30</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>3.023</td>\n",
       "      <td>-12.438</td>\n",
       "      <td>-1.997</td>\n",
       "      <td>0.112</td>\n",
       "      <td>1.946</td>\n",
       "      <td>10.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V31</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.469</td>\n",
       "      <td>3.446</td>\n",
       "      <td>-11.263</td>\n",
       "      <td>-1.822</td>\n",
       "      <td>0.486</td>\n",
       "      <td>2.779</td>\n",
       "      <td>12.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V32</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>5.586</td>\n",
       "      <td>-17.244</td>\n",
       "      <td>-3.556</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>3.752</td>\n",
       "      <td>26.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V33</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>3.539</td>\n",
       "      <td>-14.904</td>\n",
       "      <td>-2.348</td>\n",
       "      <td>-0.160</td>\n",
       "      <td>2.099</td>\n",
       "      <td>13.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V34</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>3.166</td>\n",
       "      <td>-14.700</td>\n",
       "      <td>-2.010</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>1.465</td>\n",
       "      <td>12.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V35</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>2.211</td>\n",
       "      <td>2.948</td>\n",
       "      <td>-12.261</td>\n",
       "      <td>0.322</td>\n",
       "      <td>2.112</td>\n",
       "      <td>4.032</td>\n",
       "      <td>13.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V36</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>1.595</td>\n",
       "      <td>3.775</td>\n",
       "      <td>-12.736</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>1.703</td>\n",
       "      <td>4.104</td>\n",
       "      <td>17.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V37</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.023</td>\n",
       "      <td>1.785</td>\n",
       "      <td>-5.079</td>\n",
       "      <td>-1.241</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.238</td>\n",
       "      <td>6.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V38</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>3.969</td>\n",
       "      <td>-15.335</td>\n",
       "      <td>-2.984</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>2.288</td>\n",
       "      <td>13.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V39</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.717</td>\n",
       "      <td>-5.451</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>0.959</td>\n",
       "      <td>2.131</td>\n",
       "      <td>7.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V40</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>-0.932</td>\n",
       "      <td>2.978</td>\n",
       "      <td>-10.076</td>\n",
       "      <td>-2.987</td>\n",
       "      <td>-1.003</td>\n",
       "      <td>1.080</td>\n",
       "      <td>8.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>5000.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count   mean   std     min    25%    50%    75%    max\n",
       "V1     4995.000 -0.278 3.466 -12.382 -2.744 -0.765  1.831 13.504\n",
       "V2     4994.000  0.398 3.140 -10.716 -1.649  0.427  2.444 14.079\n",
       "V3     5000.000  2.552 3.327  -9.238  0.315  2.260  4.587 15.315\n",
       "V4     5000.000 -0.049 3.414 -14.682 -2.293 -0.146  2.166 12.140\n",
       "V5     5000.000 -0.080 2.111  -7.712 -1.615 -0.132  1.341  7.673\n",
       "V6     5000.000 -1.042 2.005  -8.924 -2.369 -1.049  0.308  5.068\n",
       "V7     5000.000 -0.908 1.769  -8.124 -2.054 -0.940  0.212  7.616\n",
       "V8     5000.000 -0.575 3.332 -12.253 -2.642 -0.358  1.713 10.415\n",
       "V9     5000.000  0.030 2.174  -6.785 -1.456 -0.080  1.450  8.851\n",
       "V10    5000.000  0.019 2.145  -8.171 -1.353  0.166  1.511  6.599\n",
       "V11    5000.000 -2.009 3.112 -13.152 -4.050 -2.043  0.044  9.956\n",
       "V12    5000.000  1.576 2.907  -8.164 -0.450  1.488  3.563 12.984\n",
       "V13    5000.000  1.622 2.883 -11.548 -0.126  1.719  3.465 12.620\n",
       "V14    5000.000 -0.921 1.803  -7.814 -2.111 -0.896  0.272  5.734\n",
       "V15    5000.000 -2.452 3.387 -15.286 -4.479 -2.417 -0.433 11.673\n",
       "V16    5000.000 -3.019 4.264 -20.986 -5.648 -2.774 -0.178 13.976\n",
       "V17    5000.000 -0.104 3.337 -13.418 -2.228  0.047  2.112 19.777\n",
       "V18    5000.000  1.196 2.586 -12.214 -0.409  0.881  2.604 13.642\n",
       "V19    5000.000  1.210 3.385 -14.170 -1.026  1.296  3.526 12.428\n",
       "V20    5000.000  0.138 3.657 -13.720 -2.325  0.193  2.540 13.871\n",
       "V21    5000.000 -3.664 3.578 -16.341 -5.944 -3.663 -1.330 11.047\n",
       "V22    5000.000  0.962 1.640  -6.740 -0.048  0.986  2.029  7.505\n",
       "V23    5000.000 -0.422 4.057 -14.422 -3.163 -0.279  2.426 13.181\n",
       "V24    5000.000  1.089 3.968 -12.316 -1.623  0.913  3.537 17.806\n",
       "V25    5000.000  0.061 2.010  -6.770 -1.298  0.077  1.428  6.557\n",
       "V26    5000.000  1.847 3.400 -11.414 -0.242  1.917  4.156 17.528\n",
       "V27    5000.000 -0.552 4.403 -13.177 -3.663 -0.872  2.247 17.290\n",
       "V28    5000.000 -0.868 1.926  -7.933 -2.160 -0.931  0.421  7.416\n",
       "V29    5000.000 -1.096 2.655  -9.988 -2.861 -1.341  0.522 14.039\n",
       "V30    5000.000 -0.119 3.023 -12.438 -1.997  0.112  1.946 10.315\n",
       "V31    5000.000  0.469 3.446 -11.263 -1.822  0.486  2.779 12.559\n",
       "V32    5000.000  0.233 5.586 -17.244 -3.556 -0.077  3.752 26.539\n",
       "V33    5000.000 -0.080 3.539 -14.904 -2.348 -0.160  2.099 13.324\n",
       "V34    5000.000 -0.393 3.166 -14.700 -2.010 -0.172  1.465 12.146\n",
       "V35    5000.000  2.211 2.948 -12.261  0.322  2.112  4.032 13.489\n",
       "V36    5000.000  1.595 3.775 -12.736 -0.866  1.703  4.104 17.116\n",
       "V37    5000.000  0.023 1.785  -5.079 -1.241 -0.110  1.238  6.810\n",
       "V38    5000.000 -0.406 3.969 -15.335 -2.984 -0.381  2.288 13.065\n",
       "V39    5000.000  0.939 1.717  -5.451 -0.208  0.959  2.131  7.182\n",
       "V40    5000.000 -0.932 2.978 -10.076 -2.987 -1.003  1.080  8.698\n",
       "Target 5000.000  0.056 0.231   0.000  0.000  0.000  0.000  1.000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"df_test.describe().T\";\n",
       "                var nbb_formatted_code = \"df_test.describe().T\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also in the test dataset, V1 to V40 colmns have values ranging from negative to positive values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__7ciGcIDPyk"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWlGr1u1hKyk"
   },
   "source": [
    "### Plotting histograms and boxplots for all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "c2op1ZUyhKyk"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# function to plot a boxplot and a histogram along the same scale.\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to the show density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\";\n",
       "                var nbb_formatted_code = \"# function to plot a boxplot and a histogram along the same scale.\\n\\n\\ndef histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\\n    \\\"\\\"\\\"\\n    Boxplot and histogram combined\\n\\n    data: dataframe\\n    feature: dataframe column\\n    figsize: size of figure (default (12,7))\\n    kde: whether to the show density curve (default False)\\n    bins: number of bins for histogram (default None)\\n    \\\"\\\"\\\"\\n    f2, (ax_box2, ax_hist2) = plt.subplots(\\n        nrows=2,  # Number of rows of the subplot grid= 2\\n        sharex=True,  # x-axis will be shared among all subplots\\n        gridspec_kw={\\\"height_ratios\\\": (0.25, 0.75)},\\n        figsize=figsize,\\n    )  # creating the 2 subplots\\n    sns.boxplot(\\n        data=data, x=feature, ax=ax_box2, showmeans=True, color=\\\"violet\\\"\\n    )  # boxplot will be created and a star will indicate the mean value of the column\\n    sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\\\"winter\\\"\\n    ) if bins else sns.histplot(\\n        data=data, x=feature, kde=kde, ax=ax_hist2\\n    )  # For histogram\\n    ax_hist2.axvline(\\n        data[feature].mean(), color=\\\"green\\\", linestyle=\\\"--\\\"\\n    )  # Add mean to the histogram\\n    ax_hist2.axvline(\\n        data[feature].median(), color=\\\"black\\\", linestyle=\\\"-\\\"\\n    )  # Add median to the histogram\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function to plot a boxplot and a histogram along the same scale.\n",
    "\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined\n",
    "\n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to the show density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,  # Number of rows of the subplot grid= 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )  # creating the 2 subplots\n",
    "    sns.boxplot(\n",
    "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )  # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )  # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )  # Add median to the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jUaMoVvhKyl"
   },
   "source": [
    "### Plotting all the features at one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W91y_f944jan"
   },
   "outputs": [],
   "source": [
    "for feature in df_train.columns:\n",
    "    histogram_boxplot(df_train, feature, figsize=(12, 7), kde=False, bins=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are outliers in V1 to V40 charts\n",
    "- Distribution of values range from negative to positive values\n",
    "- The target column values are imbalanced, majority of the values have 0 (no failures) than 1 (faliures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knk0w9XH4jao"
   },
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JbJc1bX4jao"
   },
   "outputs": [],
   "source": [
    "# Creating a copy of the train and test dataset\n",
    "data_train = df_train.copy()\n",
    "data_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing train data into X and y\n",
    "X = data_train.drop([\"Target\"], axis=1)\n",
    "y = data_train[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and validation set, we already have a test set:\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=1, stratify=y\n",
    ")\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing test data into X_test and y_test\n",
    "X_test = data_test.drop([\"Target\"], axis=1)\n",
    "y_test = data_test[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J99-7Kubp09"
   },
   "source": [
    "## Missing value imputation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hke9uYOfBqoQ"
   },
   "outputs": [],
   "source": [
    "# creating an instace of the imputer to be used\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the train data\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "\n",
    "# Transform the validation data\n",
    "X_val = pd.DataFrame(imputer.fit_transform(X_val), columns=X_train.columns)\n",
    "\n",
    "# Transform the test data\n",
    "X_test = pd.DataFrame(imputer.fit_transform(X_test), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that no column has missing values in train or test sets\n",
    "print(X_train.isna().sum())\n",
    "print(\"-\" * 30)\n",
    "print(X_val.isna().sum())\n",
    "print(\"-\" * 30)\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No missing values in train, validation and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzOa9FGA6WtG"
   },
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZqmoqz7bp0-"
   },
   "source": [
    "### Model evaluation criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2ORUgmUjDZC"
   },
   "source": [
    "The nature of predictions made by the classification model will translate as follows:\n",
    "\n",
    "- True positives (TP) are failures correctly predicted by the model.\n",
    "- False negatives (FN) are real failures in a generator where there is no detection by model. \n",
    "- False positives (FP) are failure detections in a generator where there is no failure.\n",
    "\n",
    "**Which metric to optimize?**\n",
    "\n",
    "* We need to choose the metric which will ensure that the maximum number of generator failures are predicted correctly by the model.\n",
    "* We would want Recall to be maximized as greater the Recall, the higher the chances of minimizing false negatives.\n",
    "* We want to minimize false negatives because if a model predicts that a machine will have no failure when there will be a failure, it will increase the maintenance cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djQTqGKU4jap"
   },
   "source": [
    "**Let's define a function to output different metrics (including recall) on the train and test set and a function to show confusion matrix so that we do not have to use the same code repetitively while evaluating models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIekBxwp4jaq"
   },
   "outputs": [],
   "source": [
    "# defining a function to compute different metrics to check performance of a classification model built using sklearn\n",
    "def model_performance_classification_sklearn(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "\n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "\n",
    "    # predicting using the independent variables\n",
    "    pred = model.predict(predictors)\n",
    "\n",
    "    acc = accuracy_score(target, pred)  # to compute Accuracy\n",
    "    recall = recall_score(target, pred)  # to compute Recall\n",
    "    precision = precision_score(target, pred)  # to compute Precision\n",
    "    f1 = f1_score(target, pred)  # to compute F1-score\n",
    "\n",
    "    # creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\"Accuracy\": acc, \"Recall\": recall, \"Precision\": precision, \"F1\": f1},\n",
    "        index=[0],\n",
    "    )\n",
    "\n",
    "    return df_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hOzddAXbp0_"
   },
   "source": [
    "### Defining scorer to be used for cross-validation and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzLUm-eSi_cJ"
   },
   "source": [
    "- We want to reduce false negatives and will try to maximize \"Recall\".\n",
    "- To maximize Recall, we can use Recall as a **scorer** in cross-validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayLcyOLsbp0_"
   },
   "outputs": [],
   "source": [
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(metrics.recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqCDCbcw4jas"
   },
   "source": [
    "### Model Building with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "V-tpzI7g4jas"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: 0.7235192266070268\n",
      "GBM: 0.7066661857008874\n",
      "Adaboost: 0.6309140754635308\n",
      "Xgboost: 0.7956208065796118\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "dtree: 0.7050359712230215\n",
      "Logistic regression: 0.48201438848920863\n",
      "Bagging: 0.7302158273381295\n",
      "Random forest: 0.7266187050359713\n",
      "GBM: 0.7230215827338129\n",
      "Adaboost: 0.6762589928057554\n",
      "Xgboost: 0.8201438848920863\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train, y_train)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "\n",
    "results1 = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train, y=y_train, scoring=scorer, cv=kfold\n",
    "    )\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    scores = recall_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the chart we will pick 4 models that performed well for further hyperparameter tuning;\n",
    "    - Decision Tree\n",
    "    - Bagging\n",
    "    - Random  Forest\n",
    "    - XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBKJaFU24jas"
   },
   "source": [
    "### Model Building with Oversampled data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FKxnygkE4jat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 832\n",
      "Before OverSampling, counts of label '0': 14168 \n",
      "\n",
      "After OverSampling, counts of label '1': 14168\n",
      "After OverSampling, counts of label '0': 14168 \n",
      "\n",
      "After OverSampling, the shape of train_X: (28336, 40)\n",
      "After OverSampling, the shape of train_y: (28336,) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"print(\\\"Before OverSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\\n\\nprint(\\\"After OverSampling, counts of label '1': {}\\\".format(sum(y_train_over == 1)))\\nprint(\\\"After OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_over == 0)))\\n\\n\\nprint(\\\"After OverSampling, the shape of train_X: {}\\\".format(X_train_over.shape))\\nprint(\\\"After OverSampling, the shape of train_y: {} \\\\n\\\".format(y_train_over.shape))\";\n",
       "                var nbb_formatted_code = \"print(\\\"Before OverSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Synthetic Minority Over Sampling Technique\\nsm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\\nX_train_over, y_train_over = sm.fit_resample(X_train, y_train)\\n\\nprint(\\\"After OverSampling, counts of label '1': {}\\\".format(sum(y_train_over == 1)))\\nprint(\\\"After OverSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_over == 0)))\\n\\n\\nprint(\\\"After OverSampling, the shape of train_X: {}\\\".format(X_train_over.shape))\\nprint(\\\"After OverSampling, the shape of train_y: {} \\\\n\\\".format(y_train_over.shape))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "# Synthetic Minority Over Sampling Technique\n",
    "sm = SMOTE(sampling_strategy=1, k_neighbors=5, random_state=1)\n",
    "X_train_over, y_train_over = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_over == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {} \\n\".format(sum(y_train_over == 0)))\n",
    "\n",
    "\n",
    "print(\"After OverSampling, the shape of train_X: {}\".format(X_train_over.shape))\n",
    "print(\"After OverSampling, the shape of train_y: {} \\n\".format(y_train_over.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "uYDlbnUO4jat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation performance on training dataset:\n",
      "\n",
      "dtree: 0.9720494245534969\n",
      "Logistic regression: 0.883963699328486\n",
      "Bagging: 0.9762141471581656\n",
      "Random forest: 0.9839075260047615\n",
      "GBM: 0.9256068151319724\n",
      "Adaboost: 0.8978689011775473\n",
      "Xgboost: 0.989554053559209\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "dtree: 0.7769784172661871\n",
      "Logistic regression: 0.8489208633093526\n",
      "Bagging: 0.8345323741007195\n",
      "Random forest: 0.8489208633093526\n",
      "GBM: 0.8776978417266187\n",
      "Adaboost: 0.8561151079136691\n",
      "Xgboost: 0.8669064748201439\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train_over, y_train_over)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train_over, y_train_over)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "\n",
    "results1 = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_over, y=y_train_over, scoring=scorer, cv=kfold\n",
    "    )\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_over, y_train_over)\n",
    "    scores = recall_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the chart we will pick 4 models that performed well for further hyperparameter tuning, this is the same in the original data performance: Decision Tree, Bagging, Random  Forest and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aimb6bn4jat"
   },
   "source": [
    "### Model Building with Undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "DhxfTkvu4jat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before UnderSampling, counts of label '1': 832\n",
      "Before UnderSampling, counts of label '0': 14168 \n",
      "\n",
      "After UnderSampling, counts of label '1': 832\n",
      "After UnderSampling, counts of label '0': 832 \n",
      "\n",
      "After UnderSampling, the shape of train_X: (1664, 40)\n",
      "After UnderSampling, the shape of train_y: (1664,) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"print(\\\"Before UnderSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Random undersampler for under sampling the data\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"After UnderSampling, counts of label '1': {}\\\".format(sum(y_train_un == 1)))\\nprint(\\\"After UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_un == 0)))\\n\\n\\nprint(\\\"After UnderSampling, the shape of train_X: {}\\\".format(X_train_un.shape))\\nprint(\\\"After UnderSampling, the shape of train_y: {} \\\\n\\\".format(y_train_un.shape))\";\n",
       "                var nbb_formatted_code = \"print(\\\"Before UnderSampling, counts of label '1': {}\\\".format(sum(y_train == 1)))\\nprint(\\\"Before UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train == 0)))\\n\\n# Random undersampler for under sampling the data\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\\n\\n\\nprint(\\\"After UnderSampling, counts of label '1': {}\\\".format(sum(y_train_un == 1)))\\nprint(\\\"After UnderSampling, counts of label '0': {} \\\\n\\\".format(sum(y_train_un == 0)))\\n\\n\\nprint(\\\"After UnderSampling, the shape of train_X: {}\\\".format(X_train_un.shape))\\nprint(\\\"After UnderSampling, the shape of train_y: {} \\\\n\\\".format(y_train_un.shape))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Before UnderSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before UnderSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    "\n",
    "# Random undersampler for under sampling the data\n",
    "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"After UnderSampling, counts of label '1': {}\".format(sum(y_train_un == 1)))\n",
    "print(\"After UnderSampling, counts of label '0': {} \\n\".format(sum(y_train_un == 0)))\n",
    "\n",
    "\n",
    "print(\"After UnderSampling, the shape of train_X: {}\".format(X_train_un.shape))\n",
    "print(\"After UnderSampling, the shape of train_y: {} \\n\".format(y_train_un.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "jROP_DVF4jau"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation performance on training dataset:\n",
      "\n",
      "dtree: 0.8617776495202367\n",
      "Logistic regression: 0.8726138085275232\n",
      "Bagging: 0.8641945025611427\n",
      "Random forest: 0.9038669648654498\n",
      "GBM: 0.8978572974532861\n",
      "Adaboost: 0.8666113556020489\n",
      "Xgboost: 0.9074742082100858\n",
      "\n",
      "Validation Performance:\n",
      "\n",
      "dtree: 0.841726618705036\n",
      "Logistic regression: 0.8525179856115108\n",
      "Bagging: 0.8705035971223022\n",
      "Random forest: 0.8920863309352518\n",
      "GBM: 0.8884892086330936\n",
      "Adaboost: 0.8489208633093526\n",
      "Xgboost: 0.9028776978417267\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train_un, y_train_un)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_formatted_code = \"models = []  # Empty list to store all the models\\n\\n# Appending models into the list\\nmodels.append((\\\"dtree\\\", DecisionTreeClassifier(random_state=1)))\\nmodels.append((\\\"Logistic regression\\\", LogisticRegression(random_state=1)))\\nmodels.append((\\\"Bagging\\\", BaggingClassifier(random_state=1)))\\nmodels.append((\\\"Random forest\\\", RandomForestClassifier(random_state=1)))\\nmodels.append((\\\"GBM\\\", GradientBoostingClassifier(random_state=1)))\\nmodels.append((\\\"Adaboost\\\", AdaBoostClassifier(random_state=1)))\\nmodels.append((\\\"Xgboost\\\", XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")))\\n\\nresults1 = []  # Empty list to store all model's CV scores\\nnames = []  # Empty list to store name of the models\\n\\n\\n# loop through all models to get the mean cross validated score\\nprint(\\\"\\\\n\\\" \\\"Cross-Validation performance on training dataset:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    kfold = StratifiedKFold(\\n        n_splits=5, shuffle=True, random_state=1\\n    )  # Setting number of splits equal to 5\\n    cv_result = cross_val_score(\\n        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\\n    )\\n    results1.append(cv_result)\\n    names.append(name)\\n    print(\\\"{}: {}\\\".format(name, cv_result.mean()))\\n\\nprint(\\\"\\\\n\\\" \\\"Validation Performance:\\\" \\\"\\\\n\\\")\\n\\nfor name, model in models:\\n    model.fit(X_train_un, y_train_un)\\n    scores = recall_score(y_val, model.predict(X_val))\\n    print(\\\"{}: {}\\\".format(name, scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []  # Empty list to store all the models\n",
    "\n",
    "# Appending models into the list\n",
    "models.append((\"dtree\", DecisionTreeClassifier(random_state=1)))\n",
    "models.append((\"Logistic regression\", LogisticRegression(random_state=1)))\n",
    "models.append((\"Bagging\", BaggingClassifier(random_state=1)))\n",
    "models.append((\"Random forest\", RandomForestClassifier(random_state=1)))\n",
    "models.append((\"GBM\", GradientBoostingClassifier(random_state=1)))\n",
    "models.append((\"Adaboost\", AdaBoostClassifier(random_state=1)))\n",
    "models.append((\"Xgboost\", XGBClassifier(random_state=1, eval_metric=\"logloss\")))\n",
    "\n",
    "results1 = []  # Empty list to store all model's CV scores\n",
    "names = []  # Empty list to store name of the models\n",
    "\n",
    "\n",
    "# loop through all models to get the mean cross validated score\n",
    "print(\"\\n\" \"Cross-Validation performance on training dataset:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(\n",
    "        n_splits=5, shuffle=True, random_state=1\n",
    "    )  # Setting number of splits equal to 5\n",
    "    cv_result = cross_val_score(\n",
    "        estimator=model, X=X_train_un, y=y_train_un, scoring=scorer, cv=kfold\n",
    "    )\n",
    "    results1.append(cv_result)\n",
    "    names.append(name)\n",
    "    print(\"{}: {}\".format(name, cv_result.mean()))\n",
    "\n",
    "print(\"\\n\" \"Validation Performance:\" \"\\n\")\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_un, y_train_un)\n",
    "    scores = recall_score(y_val, model.predict(X_val))\n",
    "    print(\"{}: {}\".format(name, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plotting boxplots for CV scores of all models defined above\\nfig = plt.figure(figsize=(10, 7))\\n\\nfig.suptitle(\\\"Algorithm Comparison\\\")\\nax = fig.add_subplot(111)\\n\\nplt.boxplot(results1)\\nax.set_xticklabels(names)\\n\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting boxplots for CV scores of all models defined above\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "fig.suptitle(\"Algorithm Comparison\")\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.boxplot(results1)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To maintain the same best models from original and oversampling we will use Decision Tree, Bagging, Random  Forest and XGBoost for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZGY1eL84jau"
   },
   "source": [
    "## HyperparameterTuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxM3jQuK_Pqc"
   },
   "source": [
    "### Sample Parameter Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czq7BZ5b4jau"
   },
   "source": [
    "**Hyperparameter tuning can take a long time to run, so to avoid that time complexity - you can use the following grids, wherever required.**\n",
    "\n",
    "- For Gradient Boosting:\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": np.arange(100,150,25),\n",
    "    \"learning_rate\": [0.2, 0.05, 1],\n",
    "    \"subsample\":[0.5,0.7], \n",
    "    \"max_features\":[0.5,0.7]\n",
    "}\n",
    "\n",
    "- For Adaboost:\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 150, 200],\n",
    "    \"learning_rate\": [0.2, 0.05],\n",
    "    \"base_estimator\": [DecisionTreeClassifier(max_depth=1, random_state=1), DecisionTreeClassifier(max_depth=2, random_state=1), DecisionTreeClassifier(max_depth=3, random_state=1),\n",
    "    ]\n",
    "}\n",
    "\n",
    "- For Bagging Classifier:\n",
    "\n",
    "param_grid = {\n",
    "    'max_samples': [0.8,0.9,1], \n",
    "    'max_features': [0.7,0.8,0.9],\n",
    "    'n_estimators' : [30,50,70],\n",
    "}\n",
    "\n",
    "- For Random Forest:\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200,250,300],\n",
    "    \"min_samples_leaf\": np.arange(1, 4),\n",
    "    \"max_features\": [np.arange(0.3, 0.6, 0.1),'sqrt'],\n",
    "    \"max_samples\": np.arange(0.4, 0.7, 0.1)\n",
    "}\n",
    "\n",
    "- For Decision Trees:\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': np.arange(2,6), \n",
    "    'min_samples_leaf': [1, 4, 7],\n",
    "    'max_leaf_nodes' : [10, 15],\n",
    "    'min_impurity_decrease': [0.0001,0.001]\n",
    "}\n",
    "\n",
    "- For Logistic Regression:\n",
    "\n",
    "param_grid = {'C': np.arange(0.1,1.1,0.1)}\n",
    "\n",
    "- For XGBoost:\n",
    "\n",
    "param_grid={\n",
    "    'n_estimators': [150, 200, 250],\n",
    "    'scale_pos_weight': [5,10],\n",
    "    'learning_rate': [0.1,0.2],\n",
    "    'gamma': [0,3,5],\n",
    "    'subsample': [0.8,0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMReRXdH_YUd"
   },
   "source": [
    "### Decision tree with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "o9kks1hG_Xhy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'min_samples_leaf': 7, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 15, 'max_depth': 5} with CV score=0.5684366207344347:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 6),\\n    \\\"min_samples_leaf\\\": [1, 4, 7],\\n    \\\"max_leaf_nodes\\\": [10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 6),\\n    \\\"min_samples_leaf\\\": [1, 4, 7],\\n    \\\"max_leaf_nodes\\\": [10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_depth\": np.arange(2, 6),\n",
    "    \"min_samples_leaf\": [1, 4, 7],\n",
    "    \"max_leaf_nodes\": [10, 15],\n",
    "    \"min_impurity_decrease\": [0.0001, 0.001],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.0001, min_samples_leaf=7,\n",
       "                       random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.0001, min_samples_leaf=7,\n",
       "                       random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.0001, min_samples_leaf=7,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\ndt_orig = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=5,\\n    min_samples_leaf=7,\\n    max_leaf_nodes=15,\\n    min_impurity_decrease=0.0001,\\n)\\n\\n\\n# Fit the model on training data\\ndt_orig.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\ndt_orig = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=5,\\n    min_samples_leaf=7,\\n    max_leaf_nodes=15,\\n    min_impurity_decrease=0.0001,\\n)\\n\\n\\n# Fit the model on training data\\ndt_orig.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "dt_orig = DecisionTreeClassifier(\n",
    "    random_state=1,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=7,\n",
    "    max_leaf_nodes=15,\n",
    "    min_impurity_decrease=0.0001,\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on training data\n",
    "dt_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.974   0.591      0.904 0.715"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"dt_train_orig = model_performance_classification_sklearn(dt_orig, X_train, y_train)\\ndt_train_orig\";\n",
       "                var nbb_formatted_code = \"dt_train_orig = model_performance_classification_sklearn(dt_orig, X_train, y_train)\\ndt_train_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_train_orig = model_performance_classification_sklearn(dt_orig, X_train, y_train)\n",
    "dt_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.970   0.583      0.822 0.682"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"dt_val_orig = model_performance_classification_sklearn(dt_orig, X_val, y_val)\\ndt_val_orig\";\n",
       "                var nbb_formatted_code = \"dt_val_orig = model_performance_classification_sklearn(dt_orig, X_val, y_val)\\ndt_val_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_val_orig = model_performance_classification_sklearn(dt_orig, X_val, y_val)\n",
    "dt_val_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the model is performing poorly on both train and validation dataset using Recall as the parameter to score performance of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chN8hbfThKyr"
   },
   "source": [
    "### Decision tree with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tVZcJ0hv4jau"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'min_samples_leaf': 7, 'min_impurity_decrease': 0.001, 'max_leaf_nodes': 15, 'max_depth': 3} with CV score=0.9102913265648006:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 6),\\n    \\\"min_samples_leaf\\\": [1, 4, 7],\\n    \\\"max_leaf_nodes\\\": [10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 6),\\n    \\\"min_samples_leaf\\\": [1, 4, 7],\\n    \\\"max_leaf_nodes\\\": [10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_depth\": np.arange(2, 6),\n",
    "    \"min_samples_leaf\": [1, 4, 7],\n",
    "    \"max_leaf_nodes\": [10, 15],\n",
    "    \"min_impurity_decrease\": [0.0001, 0.001],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.001, min_samples_leaf=7,\n",
       "                       random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.001, min_samples_leaf=7,\n",
       "                       random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, max_leaf_nodes=15,\n",
       "                       min_impurity_decrease=0.001, min_samples_leaf=7,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\ndt_ov = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=3,\\n    min_samples_leaf=7,\\n    max_leaf_nodes=15,\\n    min_impurity_decrease=0.001,\\n)\\n\\n# Fit the model on training data\\ndt_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\ndt_ov = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=3,\\n    min_samples_leaf=7,\\n    max_leaf_nodes=15,\\n    min_impurity_decrease=0.001,\\n)\\n\\n# Fit the model on training data\\ndt_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "dt_ov = DecisionTreeClassifier(\n",
    "    random_state=1,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=7,\n",
    "    max_leaf_nodes=15,\n",
    "    min_impurity_decrease=0.001,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "dt_ov.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.843</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.843   0.917      0.799 0.854"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"dt_train_ov = model_performance_classification_sklearn(\\n    dt_ov, X_train_over, y_train_over\\n)\\ndt_train_ov\";\n",
       "                var nbb_formatted_code = \"dt_train_ov = model_performance_classification_sklearn(\\n    dt_ov, X_train_over, y_train_over\\n)\\ndt_train_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_train_ov = model_performance_classification_sklearn(\n",
    "    dt_ov, X_train_over, y_train_over\n",
    ")\n",
    "dt_train_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.763</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.763   0.885      0.176 0.294"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"dt_val_ov = model_performance_classification_sklearn(dt_ov, X_val, y_val)\\ndt_val_ov\";\n",
       "                var nbb_formatted_code = \"dt_val_ov = model_performance_classification_sklearn(dt_ov, X_val, y_val)\\ndt_val_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_val_ov = model_performance_classification_sklearn(dt_ov, X_val, y_val)\n",
    "dt_val_ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From Recall, there is overfitting in the train data set, though Precision and F1 score has poor perfomance in validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtPIiIS7hKyr"
   },
   "source": [
    "### Decision tree with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5pbdykhHhKyr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'min_samples_leaf': 1, 'min_impurity_decrease': 0.001, 'max_leaf_nodes': 5, 'max_depth': 2} with CV score=0.850811629752543:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 20),\\n    \\\"min_samples_leaf\\\": [1, 2, 5, 7],\\n    \\\"max_leaf_nodes\\\": [5, 10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = DecisionTreeClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_depth\\\": np.arange(2, 20),\\n    \\\"min_samples_leaf\\\": [1, 2, 5, 7],\\n    \\\"max_leaf_nodes\\\": [5, 10, 15],\\n    \\\"min_impurity_decrease\\\": [0.0001, 0.001],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_depth\": np.arange(2, 20),\n",
    "    \"min_samples_leaf\": [1, 2, 5, 7],\n",
    "    \"max_leaf_nodes\": [5, 10, 15],\n",
    "    \"min_impurity_decrease\": [0.0001, 0.001],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_un, y_train_un)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, max_leaf_nodes=5,\n",
       "                       min_impurity_decrease=0.001, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, max_leaf_nodes=5,\n",
       "                       min_impurity_decrease=0.001, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, max_leaf_nodes=5,\n",
       "                       min_impurity_decrease=0.001, random_state=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\ndt_un = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=2,\\n    min_samples_leaf=1,\\n    max_leaf_nodes=5,\\n    min_impurity_decrease=0.001,\\n)\\n\\n\\n# Fit the model on training data\\ndt_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\ndt_un = DecisionTreeClassifier(\\n    random_state=1,\\n    max_depth=2,\\n    min_samples_leaf=1,\\n    max_leaf_nodes=5,\\n    min_impurity_decrease=0.001,\\n)\\n\\n\\n# Fit the model on training data\\ndt_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "dt_un = DecisionTreeClassifier(\n",
    "    random_state=1,\n",
    "    max_depth=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_leaf_nodes=5,\n",
    "    min_impurity_decrease=0.001,\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on training data\n",
    "dt_un.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.764</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.764   0.909      0.705 0.794"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"dt_train_un = model_performance_classification_sklearn(dt_un, X_train_un, y_train_un)\\ndt_train_un\";\n",
       "                var nbb_formatted_code = \"dt_train_un = model_performance_classification_sklearn(dt_un, X_train_un, y_train_un)\\ndt_train_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_train_un = model_performance_classification_sklearn(dt_un, X_train_un, y_train_un)\n",
    "dt_train_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.609</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.609   0.888      0.114 0.202"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"dt_val_un = model_performance_classification_sklearn(dt_un, X_val, y_val)\\ndt_val_un\";\n",
       "                var nbb_formatted_code = \"dt_val_un = model_performance_classification_sklearn(dt_un, X_val, y_val)\\ndt_val_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_val_un = model_performance_classification_sklearn(dt_un, X_val, y_val)\n",
    "dt_val_un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model is performing well in Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 70, 'max_samples': 0.8, 'max_features': 0.9} with CV score=0.7308563595700166:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = BaggingClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_samples\": [0.8, 0.9, 1],\n",
    "    \"max_features\": [0.7, 0.8, 0.9],\n",
    "    \"n_estimators\": [30, 50, 70],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(max_features=0.9, max_samples=0.8, n_estimators=70,\n",
       "                  random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(max_features=0.9, max_samples=0.8, n_estimators=70,\n",
       "                  random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(max_features=0.9, max_samples=0.8, n_estimators=70,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nbag_orig = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.8, max_features=0.9\\n)\\n\\n# Fit the model on training data\\nbag_orig.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nbag_orig = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.8, max_features=0.9\\n)\\n\\n# Fit the model on training data\\nbag_orig.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "bag_orig = BaggingClassifier(\n",
    "    random_state=1, n_estimators=70, max_samples=0.8, max_features=0.9\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "bag_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.999   0.978      1.000 0.989"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"bag_train_orig = model_performance_classification_sklearn(bag_orig, X_train, y_train)\\nbag_train_orig\";\n",
       "                var nbb_formatted_code = \"bag_train_orig = model_performance_classification_sklearn(bag_orig, X_train, y_train)\\nbag_train_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_train_orig = model_performance_classification_sklearn(bag_orig, X_train, y_train)\n",
    "bag_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.984   0.737      0.958 0.833"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"bag_val_orig = model_performance_classification_sklearn(bag_orig, X_val, y_val)\\nbag_val_orig\";\n",
       "                var nbb_formatted_code = \"bag_val_orig = model_performance_classification_sklearn(bag_orig, X_val, y_val)\\nbag_val_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_val_orig = model_performance_classification_sklearn(bag_orig, X_val, y_val)\n",
    "bag_val_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is a slight overfitting in Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 70, 'max_samples': 0.9, 'max_features': 0.8} with CV score=0.9828488269988673:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = BaggingClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_samples\": [0.8, 0.9, 1],\n",
    "    \"max_features\": [0.7, 0.8, 0.9],\n",
    "    \"n_estimators\": [30, 50, 70],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(max_features=0.8, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(max_features=0.8, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(max_features=0.8, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nbag_ov = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.8\\n)\\n\\n# Fit the model on training data\\nbag_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nbag_ov = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.8\\n)\\n\\n# Fit the model on training data\\nbag_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "bag_ov = BaggingClassifier(\n",
    "    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.8\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "bag_ov.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     1.000   1.000      1.000 1.000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"bag_train_ov = model_performance_classification_sklearn(\\n    bag_ov, X_train_over, y_train_over\\n)\\nbag_train_ov\";\n",
       "                var nbb_formatted_code = \"bag_train_ov = model_performance_classification_sklearn(\\n    bag_ov, X_train_over, y_train_over\\n)\\nbag_train_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_train_ov = model_performance_classification_sklearn(\n",
    "    bag_ov, X_train_over, y_train_over\n",
    ")\n",
    "bag_train_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.986   0.867      0.883 0.875"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"bag_val_ov = model_performance_classification_sklearn(bag_ov, X_val, y_val)\\nbag_val_ov\";\n",
       "                var nbb_formatted_code = \"bag_val_ov = model_performance_classification_sklearn(bag_ov, X_val, y_val)\\nbag_val_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_val_ov = model_performance_classification_sklearn(bag_ov, X_val, y_val)\n",
    "bag_val_ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is overfitting in the train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 70, 'max_samples': 0.9, 'max_features': 0.9} with CV score=0.8966236202294207:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = BaggingClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"max_samples\\\": [0.8, 0.9, 1],\\n    \\\"max_features\\\": [0.7, 0.8, 0.9],\\n    \\\"n_estimators\\\": [30, 50, 70],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = BaggingClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"max_samples\": [0.8, 0.9, 1],\n",
    "    \"max_features\": [0.7, 0.8, 0.9],\n",
    "    \"n_estimators\": [30, 50, 70],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_un, y_train_un)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(max_features=0.9, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(max_features=0.9, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(max_features=0.9, max_samples=0.9, n_estimators=70,\n",
       "                  random_state=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nbag_un = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.9\\n)\\n\\n# Fit the model on training data\\nbag_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nbag_un = BaggingClassifier(\\n    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.9\\n)\\n\\n# Fit the model on training data\\nbag_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "bag_un = BaggingClassifier(\n",
    "    random_state=1, n_estimators=70, max_samples=0.9, max_features=0.9\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "bag_un.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     1.000   1.000      1.000 1.000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"bag_train_un = model_performance_classification_sklearn(bag_un, X_train_un, y_train_un)\\nbag_train_un\";\n",
       "                var nbb_formatted_code = \"bag_train_un = model_performance_classification_sklearn(bag_un, X_train_un, y_train_un)\\nbag_train_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_train_un = model_performance_classification_sklearn(bag_un, X_train_un, y_train_un)\n",
    "bag_train_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.938   0.896      0.469 0.616"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"bag_val_un = model_performance_classification_sklearn(bag_un, X_val, y_val)\\nbag_val_un\";\n",
       "                var nbb_formatted_code = \"bag_val_un = model_performance_classification_sklearn(bag_un, X_val, y_val)\\nbag_val_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bag_val_un = model_performance_classification_sklearn(bag_un, X_val, y_val)\n",
    "bag_val_un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is also overfitting in the train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 250, 'min_samples_leaf': 1, 'max_samples': 0.6, 'max_features': 'sqrt'} with CV score=0.6996248466921577:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = param_grid = {\n",
    "    \"n_estimators\": [200, 250, 300],\n",
    "    \"min_samples_leaf\": np.arange(1, 4),\n",
    "    \"max_features\": [np.arange(0.3, 0.6, 0.1), \"sqrt\"],\n",
    "    \"max_samples\": np.arange(0.4, 0.7, 0.1),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nrf_orig = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n\\n# Fit the model on training data\\nrf_orig.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nrf_orig = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n\\n# Fit the model on training data\\nrf_orig.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "rf_orig = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_estimators=250,\n",
    "    min_samples_leaf=1,\n",
    "    max_samples=0.6,\n",
    "    max_features=\"sqrt\",\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "rf_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.909</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.995   0.909      1.000 0.952"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"rf_train_orig = model_performance_classification_sklearn(rf_orig, X_train, y_train)\\nrf_train_orig\";\n",
       "                var nbb_formatted_code = \"rf_train_orig = model_performance_classification_sklearn(rf_orig, X_train, y_train)\\nrf_train_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_train_orig = model_performance_classification_sklearn(rf_orig, X_train, y_train)\n",
    "rf_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.983   0.712      0.985 0.827"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"rf_val_orig = model_performance_classification_sklearn(rf_orig, X_val, y_val)\\nrf_val_orig\";\n",
       "                var nbb_formatted_code = \"rf_val_orig = model_performance_classification_sklearn(rf_orig, X_val, y_val)\\nrf_val_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_val_orig = model_performance_classification_sklearn(rf_orig, X_val, y_val)\n",
    "rf_val_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is overfitting in Recall parameter, others parameters are fitting well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 300, 'min_samples_leaf': 1, 'max_samples': 0.6, 'max_features': 'sqrt'} with CV score=0.9815078165615898:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = param_grid = {\n",
    "    \"n_estimators\": [200, 250, 300],\n",
    "    \"min_samples_leaf\": np.arange(1, 4),\n",
    "    \"max_features\": [np.arange(0.3, 0.6, 0.1), \"sqrt\"],\n",
    "    \"max_samples\": np.arange(0.4, 0.7, 0.1),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=300, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=300, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_samples=0.6, n_estimators=300, random_state=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nrf_ov = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=300,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n# Fit the model on training data\\nrf_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nrf_ov = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=300,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n# Fit the model on training data\\nrf_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "rf_ov = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_estimators=300,\n",
    "    min_samples_leaf=1,\n",
    "    max_samples=0.6,\n",
    "    max_features=\"sqrt\",\n",
    ")\n",
    "# Fit the model on training data\n",
    "rf_ov.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     1.000   0.999      1.000 1.000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"rf_train_ov = model_performance_classification_sklearn(\\n    rf_ov, X_train_over, y_train_over\\n)\\nrf_train_ov\";\n",
       "                var nbb_formatted_code = \"rf_train_ov = model_performance_classification_sklearn(\\n    rf_ov, X_train_over, y_train_over\\n)\\nrf_train_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_train_ov = model_performance_classification_sklearn(\n",
    "    rf_ov, X_train_over, y_train_over\n",
    ")\n",
    "rf_train_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.988   0.860      0.926 0.892"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"rf_val_ov = model_performance_classification_sklearn(rf_ov, X_val, y_val)\\nrf_val_ov\";\n",
       "                var nbb_formatted_code = \"rf_val_ov = model_performance_classification_sklearn(rf_ov, X_val, y_val)\\nrf_val_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_val_ov = model_performance_classification_sklearn(rf_ov, X_val, y_val)\n",
    "rf_val_ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is also overfitting in Recall, other parameters are peforming well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 250, 'min_samples_leaf': 1, 'max_samples': 0.6, 'max_features': 'sqrt'} with CV score=0.8978140105331505:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 67;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = RandomForestClassifier(random_state=1)\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = param_grid = {\\n    \\\"n_estimators\\\": [200, 250, 300],\\n    \\\"min_samples_leaf\\\": np.arange(1, 4),\\n    \\\"max_features\\\": [np.arange(0.3, 0.6, 0.1), \\\"sqrt\\\"],\\n    \\\"max_samples\\\": np.arange(0.4, 0.7, 0.1),\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = param_grid = {\n",
    "    \"n_estimators\": [200, 250, 300],\n",
    "    \"min_samples_leaf\": np.arange(1, 4),\n",
    "    \"max_features\": [np.arange(0.3, 0.6, 0.1), \"sqrt\"],\n",
    "    \"max_samples\": np.arange(0.4, 0.7, 0.1),\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_un, y_train_un)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_samples=0.6, n_estimators=250, random_state=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 68;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nrf_un = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n\\n\\n# Fit the model on training data\\nrf_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nrf_un = RandomForestClassifier(\\n    random_state=1,\\n    n_estimators=250,\\n    min_samples_leaf=1,\\n    max_samples=0.6,\\n    max_features=\\\"sqrt\\\",\\n)\\n\\n\\n# Fit the model on training data\\nrf_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "rf_un = RandomForestClassifier(\n",
    "    random_state=1,\n",
    "    n_estimators=250,\n",
    "    min_samples_leaf=1,\n",
    "    max_samples=0.6,\n",
    "    max_features=\"sqrt\",\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on training data\n",
    "rf_un.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.988   0.977      0.999 0.988"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"rf_train_un = model_performance_classification_sklearn(rf_un, X_train_un, y_train_un)\\nrf_train_un\";\n",
       "                var nbb_formatted_code = \"rf_train_un = model_performance_classification_sklearn(rf_un, X_train_un, y_train_un)\\nrf_train_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_train_un = model_performance_classification_sklearn(rf_un, X_train_un, y_train_un)\n",
    "rf_train_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.944   0.885      0.496 0.636"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 70;\n",
       "                var nbb_unformatted_code = \"rf_val_un = model_performance_classification_sklearn(rf_un, X_val, y_val)\\nrf_val_un\";\n",
       "                var nbb_formatted_code = \"rf_val_un = model_performance_classification_sklearn(rf_un, X_val, y_val)\\nrf_val_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_val_un = model_performance_classification_sklearn(rf_un, X_val, y_val)\n",
    "rf_val_un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is overfitting in Recall, other parameters Precission and F1 score are performing poorly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'subsample': 0.8, 'scale_pos_weight': 10, 'n_estimators': 150, 'learning_rate': 0.1, 'gamma': 3} with CV score=0.8570088738186279:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 71;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train, y_train)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": [150, 200, 250],\n",
    "    \"scale_pos_weight\": [5, 10],\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    \"gamma\": [0, 3, 5],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=3, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=150, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.8,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=3, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=150, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.8,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=3, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=150, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 72;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nxgb_orig = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.8,\\n    scale_pos_weight=10,\\n    n_estimators=150,\\n    learning_rate=0.1,\\n    gamma=3,\\n)\\n\\n# Fit the model on training data\\nxgb_orig.fit(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nxgb_orig = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.8,\\n    scale_pos_weight=10,\\n    n_estimators=150,\\n    learning_rate=0.1,\\n    gamma=3,\\n)\\n\\n# Fit the model on training data\\nxgb_orig.fit(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "xgb_orig = XGBClassifier(\n",
    "    random_state=1,\n",
    "    eval_metric=\"logloss\",\n",
    "    subsample=0.8,\n",
    "    scale_pos_weight=10,\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    gamma=3,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_orig.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.999   1.000      0.988 0.994"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"xgb_train_orig = model_performance_classification_sklearn(xgb_orig, X_train, y_train)\\nxgb_train_orig\";\n",
       "                var nbb_formatted_code = \"xgb_train_orig = model_performance_classification_sklearn(xgb_orig, X_train, y_train)\\nxgb_train_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_train_orig = model_performance_classification_sklearn(xgb_orig, X_train, y_train)\n",
    "xgb_train_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.989   0.849      0.948 0.896"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 74;\n",
       "                var nbb_unformatted_code = \"xgb_val_orig = model_performance_classification_sklearn(xgb_orig, X_val, y_val)\\nxgb_val_orig\";\n",
       "                var nbb_formatted_code = \"xgb_val_orig = model_performance_classification_sklearn(xgb_orig, X_val, y_val)\\nxgb_val_orig\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_val_orig = model_performance_classification_sklearn(xgb_orig, X_val, y_val)\n",
    "xgb_val_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is overfitting in Recall parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'subsample': 0.9, 'scale_pos_weight': 10, 'n_estimators': 200, 'learning_rate': 0.2, 'gamma': 0} with CV score=0.9956240108948847:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_over, y_train_over)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": [150, 200, 250],\n",
    "    \"scale_pos_weight\": [5, 10],\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    \"gamma\": [0, 3, 5],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_over, y_train_over)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=200, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nxgb_ov = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=200,\\n    learning_rate=0.2,\\n    gamma=0,\\n)\\n\\n# Fit the model on training data\\nxgb_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nxgb_ov = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=200,\\n    learning_rate=0.2,\\n    gamma=0,\\n)\\n\\n# Fit the model on training data\\nxgb_ov.fit(X_train_over, y_train_over)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "xgb_ov = XGBClassifier(\n",
    "    random_state=1,\n",
    "    eval_metric=\"logloss\",\n",
    "    subsample=0.9,\n",
    "    scale_pos_weight=10,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.2,\n",
    "    gamma=0,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_ov.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     1.000   1.000      1.000 1.000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"xgb_train_ov = model_performance_classification_sklearn(\\n    xgb_ov, X_train_over, y_train_over\\n)\\nxgb_train_ov\";\n",
       "                var nbb_formatted_code = \"xgb_train_ov = model_performance_classification_sklearn(\\n    xgb_ov, X_train_over, y_train_over\\n)\\nxgb_train_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_train_ov = model_performance_classification_sklearn(\n",
    "    xgb_ov, X_train_over, y_train_over\n",
    ")\n",
    "xgb_train_ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.985   0.874      0.859 0.866"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 78;\n",
       "                var nbb_unformatted_code = \"xgb_val_ov = model_performance_classification_sklearn(xgb_ov, X_val, y_val)\\nxgb_val_ov\";\n",
       "                var nbb_formatted_code = \"xgb_val_ov = model_performance_classification_sklearn(xgb_ov, X_val, y_val)\\nxgb_val_ov\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_val_ov = model_performance_classification_sklearn(xgb_ov, X_val, y_val)\n",
    "xgb_val_ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There is overffitting in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'subsample': 0.9, 'scale_pos_weight': 10, 'n_estimators': 250, 'learning_rate': 0.1, 'gamma': 5} with CV score=0.9266503138301709:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_formatted_code = \"# defining model\\nModel = XGBClassifier(random_state=1, eval_metric=\\\"logloss\\\")\\n\\n# Parameter grid to pass in RandomSearchCV\\nparam_grid = {\\n    \\\"n_estimators\\\": [150, 200, 250],\\n    \\\"scale_pos_weight\\\": [5, 10],\\n    \\\"learning_rate\\\": [0.1, 0.2],\\n    \\\"gamma\\\": [0, 3, 5],\\n    \\\"subsample\\\": [0.8, 0.9],\\n}\\n\\n# Calling RandomizedSearchCV\\nrandomized_cv = RandomizedSearchCV(\\n    estimator=Model,\\n    param_distributions=param_grid,\\n    n_iter=10,\\n    n_jobs=-1,\\n    scoring=scorer,\\n    cv=5,\\n    random_state=1,\\n)\\n\\n# Fitting parameters in RandomizedSearchCV\\nrandomized_cv.fit(X_train_un, y_train_un)\\n\\nprint(\\n    \\\"Best parameters are {} with CV score={}:\\\".format(\\n        randomized_cv.best_params_, randomized_cv.best_score_\\n    )\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining model\n",
    "Model = XGBClassifier(random_state=1, eval_metric=\"logloss\")\n",
    "\n",
    "# Parameter grid to pass in RandomSearchCV\n",
    "param_grid = {\n",
    "    \"n_estimators\": [150, 200, 250],\n",
    "    \"scale_pos_weight\": [5, 10],\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    \"gamma\": [0, 3, 5],\n",
    "    \"subsample\": [0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Calling RandomizedSearchCV\n",
    "randomized_cv = RandomizedSearchCV(\n",
    "    estimator=Model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "# Fitting parameters in RandomizedSearchCV\n",
    "randomized_cv.fit(X_train_un, y_train_un)\n",
    "\n",
    "print(\n",
    "    \"Best parameters are {} with CV score={}:\".format(\n",
    "        randomized_cv.best_params_, randomized_cv.best_score_\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=5, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=250, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, gamma=5, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=250, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method=&#x27;exact&#x27;, validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              eval_metric='logloss', gamma=5, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=250, n_jobs=4,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=10, subsample=0.9,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"# building model with best parameters\\nxgb_un = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=5,\\n)\\n\\n# Fit the model on training data\\nxgb_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_formatted_code = \"# building model with best parameters\\nxgb_un = XGBClassifier(\\n    random_state=1,\\n    eval_metric=\\\"logloss\\\",\\n    subsample=0.9,\\n    scale_pos_weight=10,\\n    n_estimators=250,\\n    learning_rate=0.1,\\n    gamma=5,\\n)\\n\\n# Fit the model on training data\\nxgb_un.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# building model with best parameters\n",
    "xgb_un = XGBClassifier(\n",
    "    random_state=1,\n",
    "    eval_metric=\"logloss\",\n",
    "    subsample=0.9,\n",
    "    scale_pos_weight=10,\n",
    "    n_estimators=250,\n",
    "    learning_rate=0.1,\n",
    "    gamma=5,\n",
    ")\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_un.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.990   1.000      0.981 0.990"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 81;\n",
       "                var nbb_unformatted_code = \"xgb_train_un = model_performance_classification_sklearn(xgb_un, X_train_un, y_train_un)\\nxgb_train_un\";\n",
       "                var nbb_formatted_code = \"xgb_train_un = model_performance_classification_sklearn(xgb_un, X_train_un, y_train_un)\\nxgb_train_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_train_un = model_performance_classification_sklearn(xgb_un, X_train_un, y_train_un)\n",
    "xgb_train_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.863   0.910      0.277 0.424"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 82;\n",
       "                var nbb_unformatted_code = \"xgb_val_un = model_performance_classification_sklearn(xgb_un, X_val, y_val)\\nxgb_val_un\";\n",
       "                var nbb_formatted_code = \"xgb_val_un = model_performance_classification_sklearn(xgb_un, X_val, y_val)\\nxgb_val_un\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_val_un = model_performance_classification_sklearn(xgb_un, X_val, y_val)\n",
    "xgb_val_un"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model is performing well in Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9JNnpxa4jau"
   },
   "source": [
    "## Model performance comparison and choosing the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "0JG85rkY4jav"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training performance comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree tuned with Original data</th>\n",
       "      <th>Decision Tree tuned with oversampled data</th>\n",
       "      <th>Decision Tree tuned with undersampled data</th>\n",
       "      <th>Bagging tuned with Original data</th>\n",
       "      <th>Bagging tuned with oversampled data</th>\n",
       "      <th>Bagging tuned with undersampled data</th>\n",
       "      <th>Random Forest tuned with Original data</th>\n",
       "      <th>Random Forest tuned with oversampled data</th>\n",
       "      <th>Random Forest tuned with undersampled data</th>\n",
       "      <th>XGBoost tuned with Original data</th>\n",
       "      <th>XGBoost tuned with oversampled data</th>\n",
       "      <th>XGBoost tuned with undersampled data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.974</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.591</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.977</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.988</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.952</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Decision Tree tuned with Original data  \\\n",
       "Accuracy                                    0.974   \n",
       "Recall                                      0.591   \n",
       "Precision                                   0.904   \n",
       "F1                                          0.715   \n",
       "\n",
       "           Decision Tree tuned with oversampled data  \\\n",
       "Accuracy                                       0.843   \n",
       "Recall                                         0.917   \n",
       "Precision                                      0.799   \n",
       "F1                                             0.854   \n",
       "\n",
       "           Decision Tree tuned with undersampled data  \\\n",
       "Accuracy                                        0.764   \n",
       "Recall                                          0.909   \n",
       "Precision                                       0.705   \n",
       "F1                                              0.794   \n",
       "\n",
       "           Bagging tuned with Original data  \\\n",
       "Accuracy                              0.999   \n",
       "Recall                                0.978   \n",
       "Precision                             1.000   \n",
       "F1                                    0.989   \n",
       "\n",
       "           Bagging tuned with oversampled data  \\\n",
       "Accuracy                                 1.000   \n",
       "Recall                                   1.000   \n",
       "Precision                                1.000   \n",
       "F1                                       1.000   \n",
       "\n",
       "           Bagging tuned with undersampled data  \\\n",
       "Accuracy                                  1.000   \n",
       "Recall                                    1.000   \n",
       "Precision                                 1.000   \n",
       "F1                                        1.000   \n",
       "\n",
       "           Random Forest tuned with Original data  \\\n",
       "Accuracy                                    0.995   \n",
       "Recall                                      0.909   \n",
       "Precision                                   1.000   \n",
       "F1                                          0.952   \n",
       "\n",
       "           Random Forest tuned with oversampled data  \\\n",
       "Accuracy                                       1.000   \n",
       "Recall                                         0.999   \n",
       "Precision                                      1.000   \n",
       "F1                                             1.000   \n",
       "\n",
       "           Random Forest tuned with undersampled data  \\\n",
       "Accuracy                                        0.988   \n",
       "Recall                                          0.977   \n",
       "Precision                                       0.999   \n",
       "F1                                              0.988   \n",
       "\n",
       "           XGBoost tuned with Original data  \\\n",
       "Accuracy                              0.999   \n",
       "Recall                                1.000   \n",
       "Precision                             0.988   \n",
       "F1                                    0.994   \n",
       "\n",
       "           XGBoost tuned with oversampled data  \\\n",
       "Accuracy                                 1.000   \n",
       "Recall                                   1.000   \n",
       "Precision                                1.000   \n",
       "F1                                       1.000   \n",
       "\n",
       "           XGBoost tuned with undersampled data  \n",
       "Accuracy                                  0.990  \n",
       "Recall                                    1.000  \n",
       "Precision                                 0.981  \n",
       "F1                                        0.990  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [\\n        dt_train_orig.T,\\n        dt_train_ov.T,\\n        dt_train_un.T,\\n        bag_train_orig.T,\\n        bag_train_ov.T,\\n        bag_train_un.T,\\n        rf_train_orig.T,\\n        rf_train_ov.T,\\n        rf_train_un.T,\\n        xgb_train_orig.T,\\n        xgb_train_ov.T,\\n        xgb_train_un.T,\\n    ],\\n    axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"Decision Tree tuned with Original data\\\",\\n    \\\"Decision Tree tuned with oversampled data\\\",\\n    \\\"Decision Tree tuned with undersampled data\\\",\\n    \\\"Bagging tuned with Original data\\\",\\n    \\\"Bagging tuned with oversampled data\\\",\\n    \\\"Bagging tuned with undersampled data\\\",\\n    \\\"Random Forest tuned with Original data\\\",\\n    \\\"Random Forest tuned with oversampled data\\\",\\n    \\\"Random Forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with Original data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n    \\\"XGBoost tuned with undersampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_formatted_code = \"# training performance comparison\\n\\nmodels_train_comp_df = pd.concat(\\n    [\\n        dt_train_orig.T,\\n        dt_train_ov.T,\\n        dt_train_un.T,\\n        bag_train_orig.T,\\n        bag_train_ov.T,\\n        bag_train_un.T,\\n        rf_train_orig.T,\\n        rf_train_ov.T,\\n        rf_train_un.T,\\n        xgb_train_orig.T,\\n        xgb_train_ov.T,\\n        xgb_train_un.T,\\n    ],\\n    axis=1,\\n)\\nmodels_train_comp_df.columns = [\\n    \\\"Decision Tree tuned with Original data\\\",\\n    \\\"Decision Tree tuned with oversampled data\\\",\\n    \\\"Decision Tree tuned with undersampled data\\\",\\n    \\\"Bagging tuned with Original data\\\",\\n    \\\"Bagging tuned with oversampled data\\\",\\n    \\\"Bagging tuned with undersampled data\\\",\\n    \\\"Random Forest tuned with Original data\\\",\\n    \\\"Random Forest tuned with oversampled data\\\",\\n    \\\"Random Forest tuned with undersampled data\\\",\\n    \\\"XGBoost tuned with Original data\\\",\\n    \\\"XGBoost tuned with oversampled data\\\",\\n    \\\"XGBoost tuned with undersampled data\\\",\\n]\\nprint(\\\"Training performance comparison:\\\")\\nmodels_train_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training performance comparison\n",
    "\n",
    "models_train_comp_df = pd.concat(\n",
    "    [\n",
    "        dt_train_orig.T,\n",
    "        dt_train_ov.T,\n",
    "        dt_train_un.T,\n",
    "        bag_train_orig.T,\n",
    "        bag_train_ov.T,\n",
    "        bag_train_un.T,\n",
    "        rf_train_orig.T,\n",
    "        rf_train_ov.T,\n",
    "        rf_train_un.T,\n",
    "        xgb_train_orig.T,\n",
    "        xgb_train_ov.T,\n",
    "        xgb_train_un.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_train_comp_df.columns = [\n",
    "    \"Decision Tree tuned with Original data\",\n",
    "    \"Decision Tree tuned with oversampled data\",\n",
    "    \"Decision Tree tuned with undersampled data\",\n",
    "    \"Bagging tuned with Original data\",\n",
    "    \"Bagging tuned with oversampled data\",\n",
    "    \"Bagging tuned with undersampled data\",\n",
    "    \"Random Forest tuned with Original data\",\n",
    "    \"Random Forest tuned with oversampled data\",\n",
    "    \"Random Forest tuned with undersampled data\",\n",
    "    \"XGBoost tuned with Original data\",\n",
    "    \"XGBoost tuned with oversampled data\",\n",
    "    \"XGBoost tuned with undersampled data\",\n",
    "]\n",
    "print(\"Training performance comparison:\")\n",
    "models_train_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree validation tuned with Original data</th>\n",
       "      <th>Decision Tree validation tuned with oversampled data</th>\n",
       "      <th>Decision Tree validation tuned with undersampled data</th>\n",
       "      <th>Bagging validation tuned with Original data</th>\n",
       "      <th>Bagging validation tuned with oversampled data</th>\n",
       "      <th>Bagging validation tuned with undersampled data</th>\n",
       "      <th>Random Forest validation tuned with Original data</th>\n",
       "      <th>Random Forest validation tuned with oversampled data</th>\n",
       "      <th>Random Forest validation tuned with undersampled data</th>\n",
       "      <th>XGBoost validation tuned with Original data</th>\n",
       "      <th>XGBoost validation tuned with oversampled data</th>\n",
       "      <th>XGBoost validation tuned with undersampled data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.583</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.682</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Decision Tree validation tuned with Original data  \\\n",
       "Accuracy                                               0.970   \n",
       "Recall                                                 0.583   \n",
       "Precision                                              0.822   \n",
       "F1                                                     0.682   \n",
       "\n",
       "           Decision Tree validation tuned with oversampled data  \\\n",
       "Accuracy                                               0.763      \n",
       "Recall                                                 0.885      \n",
       "Precision                                              0.176      \n",
       "F1                                                     0.294      \n",
       "\n",
       "           Decision Tree validation tuned with undersampled data  \\\n",
       "Accuracy                                               0.609       \n",
       "Recall                                                 0.888       \n",
       "Precision                                              0.114       \n",
       "F1                                                     0.202       \n",
       "\n",
       "           Bagging validation tuned with Original data  \\\n",
       "Accuracy                                         0.984   \n",
       "Recall                                           0.737   \n",
       "Precision                                        0.958   \n",
       "F1                                               0.833   \n",
       "\n",
       "           Bagging validation tuned with oversampled data  \\\n",
       "Accuracy                                            0.986   \n",
       "Recall                                              0.867   \n",
       "Precision                                           0.883   \n",
       "F1                                                  0.875   \n",
       "\n",
       "           Bagging validation tuned with undersampled data  \\\n",
       "Accuracy                                             0.938   \n",
       "Recall                                               0.896   \n",
       "Precision                                            0.469   \n",
       "F1                                                   0.616   \n",
       "\n",
       "           Random Forest validation tuned with Original data  \\\n",
       "Accuracy                                               0.983   \n",
       "Recall                                                 0.712   \n",
       "Precision                                              0.985   \n",
       "F1                                                     0.827   \n",
       "\n",
       "           Random Forest validation tuned with oversampled data  \\\n",
       "Accuracy                                               0.988      \n",
       "Recall                                                 0.860      \n",
       "Precision                                              0.926      \n",
       "F1                                                     0.892      \n",
       "\n",
       "           Random Forest validation tuned with undersampled data  \\\n",
       "Accuracy                                               0.944       \n",
       "Recall                                                 0.885       \n",
       "Precision                                              0.496       \n",
       "F1                                                     0.636       \n",
       "\n",
       "           XGBoost validation tuned with Original data  \\\n",
       "Accuracy                                         0.989   \n",
       "Recall                                           0.849   \n",
       "Precision                                        0.948   \n",
       "F1                                               0.896   \n",
       "\n",
       "           XGBoost validation tuned with oversampled data  \\\n",
       "Accuracy                                            0.985   \n",
       "Recall                                              0.874   \n",
       "Precision                                           0.859   \n",
       "F1                                                  0.866   \n",
       "\n",
       "           XGBoost validation tuned with undersampled data  \n",
       "Accuracy                                             0.863  \n",
       "Recall                                               0.910  \n",
       "Precision                                            0.277  \n",
       "F1                                                   0.424  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"# validation performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [\\n        dt_val_orig.T,\\n        dt_val_ov.T,\\n        dt_val_un.T,\\n        bag_val_orig.T,\\n        bag_val_ov.T,\\n        bag_val_un.T,\\n        rf_val_orig.T,\\n        rf_val_ov.T,\\n        rf_val_un.T,\\n        xgb_val_orig.T,\\n        xgb_val_ov.T,\\n        xgb_val_un.T,\\n    ],\\n    axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"Decision Tree validation tuned with Original data\\\",\\n    \\\"Decision Tree validation tuned with oversampled data\\\",\\n    \\\"Decision Tree validation tuned with undersampled data\\\",\\n    \\\"Bagging validation tuned with Original data\\\",\\n    \\\"Bagging validation tuned with oversampled data\\\",\\n    \\\"Bagging validation tuned with undersampled data\\\",\\n    \\\"Random Forest validation tuned with Original data\\\",\\n    \\\"Random Forest validation tuned with oversampled data\\\",\\n    \\\"Random Forest validation tuned with undersampled data\\\",\\n    \\\"XGBoost validation tuned with Original data\\\",\\n    \\\"XGBoost validation tuned with oversampled data\\\",\\n    \\\"XGBoost validation tuned with undersampled data\\\",\\n]\\n\\n\\nprint(\\\"Validation performance comparison:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_formatted_code = \"# validation performance comparison\\n\\nmodels_val_comp_df = pd.concat(\\n    [\\n        dt_val_orig.T,\\n        dt_val_ov.T,\\n        dt_val_un.T,\\n        bag_val_orig.T,\\n        bag_val_ov.T,\\n        bag_val_un.T,\\n        rf_val_orig.T,\\n        rf_val_ov.T,\\n        rf_val_un.T,\\n        xgb_val_orig.T,\\n        xgb_val_ov.T,\\n        xgb_val_un.T,\\n    ],\\n    axis=1,\\n)\\nmodels_val_comp_df.columns = [\\n    \\\"Decision Tree validation tuned with Original data\\\",\\n    \\\"Decision Tree validation tuned with oversampled data\\\",\\n    \\\"Decision Tree validation tuned with undersampled data\\\",\\n    \\\"Bagging validation tuned with Original data\\\",\\n    \\\"Bagging validation tuned with oversampled data\\\",\\n    \\\"Bagging validation tuned with undersampled data\\\",\\n    \\\"Random Forest validation tuned with Original data\\\",\\n    \\\"Random Forest validation tuned with oversampled data\\\",\\n    \\\"Random Forest validation tuned with undersampled data\\\",\\n    \\\"XGBoost validation tuned with Original data\\\",\\n    \\\"XGBoost validation tuned with oversampled data\\\",\\n    \\\"XGBoost validation tuned with undersampled data\\\",\\n]\\n\\n\\nprint(\\\"Validation performance comparison:\\\")\\nmodels_val_comp_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validation performance comparison\n",
    "\n",
    "models_val_comp_df = pd.concat(\n",
    "    [\n",
    "        dt_val_orig.T,\n",
    "        dt_val_ov.T,\n",
    "        dt_val_un.T,\n",
    "        bag_val_orig.T,\n",
    "        bag_val_ov.T,\n",
    "        bag_val_un.T,\n",
    "        rf_val_orig.T,\n",
    "        rf_val_ov.T,\n",
    "        rf_val_un.T,\n",
    "        xgb_val_orig.T,\n",
    "        xgb_val_ov.T,\n",
    "        xgb_val_un.T,\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "models_val_comp_df.columns = [\n",
    "    \"Decision Tree validation tuned with Original data\",\n",
    "    \"Decision Tree validation tuned with oversampled data\",\n",
    "    \"Decision Tree validation tuned with undersampled data\",\n",
    "    \"Bagging validation tuned with Original data\",\n",
    "    \"Bagging validation tuned with oversampled data\",\n",
    "    \"Bagging validation tuned with undersampled data\",\n",
    "    \"Random Forest validation tuned with Original data\",\n",
    "    \"Random Forest validation tuned with oversampled data\",\n",
    "    \"Random Forest validation tuned with undersampled data\",\n",
    "    \"XGBoost validation tuned with Original data\",\n",
    "    \"XGBoost validation tuned with oversampled data\",\n",
    "    \"XGBoost validation tuned with undersampled data\",\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Validation performance comparison:\")\n",
    "models_val_comp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best model that has a good Recall in the train and validation set is Decision Tree Undersampling model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_pDMFAz4jav"
   },
   "source": [
    "### Test set final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "g8-epsXv4jav"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision    F1\n",
       "0     0.633   0.876      0.121 0.212"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"# Using Decision tree undersampled to model\\ntest_dt = model_performance_classification_sklearn(dt_un, X_test, y_test)\\ntest_dt\";\n",
       "                var nbb_formatted_code = \"# Using Decision tree undersampled to model\\ntest_dt = model_performance_classification_sklearn(dt_un, X_test, y_test)\\ntest_dt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Decision tree undersampled to model\n",
    "test_dt = model_performance_classification_sklearn(dt_un, X_test, y_test)\n",
    "test_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model Decision Tree undersampling is performing well on the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 86;\n",
       "                var nbb_unformatted_code = \"feature_names = X_train.columns\\nimportances = dt_un.feature_importances_\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(12, 12))\\nplt.title(\\\"Feature Importances\\\")\\nplt.barh(range(len(indices)), importances[indices], color=\\\"violet\\\", align=\\\"center\\\")\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"feature_names = X_train.columns\\nimportances = dt_un.feature_importances_\\nindices = np.argsort(importances)\\n\\nplt.figure(figsize=(12, 12))\\nplt.title(\\\"Feature Importances\\\")\\nplt.barh(range(len(indices)), importances[indices], color=\\\"violet\\\", align=\\\"center\\\")\\nplt.yticks(range(len(indices)), [feature_names[i] for i in indices])\\nplt.xlabel(\\\"Relative Importance\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = X_train.columns\n",
    "importances = dt_un.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], color=\"violet\", align=\"center\")\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most important features are V36, V18 and V15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM6VZTRn4jav"
   },
   "source": [
    "## Pipelines to build the final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzg12gvx4jav"
   },
   "source": [
    "- Since we have only one datatype in the data, we don't need to use column transformer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"Pipeline_model = Pipeline(\\n    [\\n        (\\\"scaler\\\", StandardScaler()),\\n        \\\"DecisionTree\\\",\\n        DecisionTreeClassifier(\\n            random_state=1,\\n            max_depth=2,\\n            min_samples_leaf=1,\\n            max_leaf_nodes=4,\\n            min_impurity_decrease=0.01,\\n        ),\\n    ]\\n)\";\n",
       "                var nbb_formatted_code = \"Pipeline_model = Pipeline(\\n    [\\n        (\\\"scaler\\\", StandardScaler()),\\n        \\\"DecisionTree\\\",\\n        DecisionTreeClassifier(\\n            random_state=1,\\n            max_depth=2,\\n            min_samples_leaf=1,\\n            max_leaf_nodes=4,\\n            min_impurity_decrease=0.01,\\n        ),\\n    ]\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pipeline_model = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        \"DecisionTree\",\n",
    "        DecisionTreeClassifier(\n",
    "            random_state=1,\n",
    "            max_depth=2,\n",
    "            min_samples_leaf=1,\n",
    "            max_leaf_nodes=4,\n",
    "            min_impurity_decrease=0.01,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"# Separating target variable and other variables\\nX1 = data_train.drop(columns=\\\"Target\\\")\\nY1 = data_train[\\\"Target\\\"]\\n\\n# Since we already have a separate test set, we don't need to divide data into train and test\\n\\nX_test1 = data_test.drop([\\\"Target\\\"], axis=1)\\ny_test1 = data_test[\\\"Target\\\"]\";\n",
       "                var nbb_formatted_code = \"# Separating target variable and other variables\\nX1 = data_train.drop(columns=\\\"Target\\\")\\nY1 = data_train[\\\"Target\\\"]\\n\\n# Since we already have a separate test set, we don't need to divide data into train and test\\n\\nX_test1 = data_test.drop([\\\"Target\\\"], axis=1)\\ny_test1 = data_test[\\\"Target\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separating target variable and other variables\n",
    "X1 = data_train.drop(columns=\"Target\")\n",
    "Y1 = data_train[\"Target\"]\n",
    "\n",
    "# Since we already have a separate test set, we don't need to divide data into train and test\n",
    "\n",
    "X_test1 = data_test.drop([\"Target\"], axis=1)\n",
    "y_test1 = data_test[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"# We can't oversample/undersample data without doing missing value treatment, so let's first treat the missing values in the train set\\nimputer = SimpleImputer(strategy=\\\"median\\\")\\nX1 = imputer.fit_transform(X1)\\n\\n# We don't need to impute missing values in test set as it will be done inside pipeline\";\n",
       "                var nbb_formatted_code = \"# We can't oversample/undersample data without doing missing value treatment, so let's first treat the missing values in the train set\\nimputer = SimpleImputer(strategy=\\\"median\\\")\\nX1 = imputer.fit_transform(X1)\\n\\n# We don't need to impute missing values in test set as it will be done inside pipeline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can't oversample/undersample data without doing missing value treatment, so let's first treat the missing values in the train set\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X1 = imputer.fit_transform(X1)\n",
    "\n",
    "# We don't need to impute missing values in test set as it will be done inside pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 90;\n",
       "                var nbb_unformatted_code = \"# code for undersampling on the data\\n# Under Sampling Technique\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# code for undersampling on the data\\n# Under Sampling Technique\\nrus = RandomUnderSampler(random_state=1, sampling_strategy=1)\\nX_train_un, y_train_un = rus.fit_resample(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code for undersampling on the data\n",
    "# Under Sampling Technique\n",
    "rus = RandomUnderSampler(random_state=1, sampling_strategy=1)\n",
    "X_train_un, y_train_un = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 91;\n",
       "                var nbb_unformatted_code = \"# Pipeline_model.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_formatted_code = \"# Pipeline_model.fit(X_train_un, y_train_un)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pipeline_model.fit(X_train_un, y_train_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 92;\n",
       "                var nbb_unformatted_code = \"# Pipeline_model_test = model_performance_classification_sklearn(\\n#    Pipeline_model, X_test1, y_test1)\\n# Pipeline_model_test\";\n",
       "                var nbb_formatted_code = \"# Pipeline_model_test = model_performance_classification_sklearn(\\n#    Pipeline_model, X_test1, y_test1)\\n# Pipeline_model_test\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pipeline_model_test = model_performance_classification_sklearn(\n",
    "#    Pipeline_model, X_test1, y_test1)\n",
    "# Pipeline_model_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5hPmHyR4jaw"
   },
   "source": [
    "# Business Insights and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSIGHTS\n",
    "\n",
    "- From the model, values in the column V36, V18 and V15 respectively are important features in the data\n",
    "- From test dataset, the model can rightly predict when a generator is due for inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIONS\n",
    "\n",
    "- A more detailed information of the different columns will enable one to give an accurate recommendations to the company\n",
    "- ReneWind shouild focus on the values in column V36, V18 and V15 as these will determine when the generators need servicing to avoid replacements which costs more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB3eO21n_sgt"
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jjFpJBnb4jak",
    "vqF4q7G94jam",
    "DVCj6_DD4jan",
    "TWlGr1u1hKyk",
    "_jUaMoVvhKyl",
    "ONL1sM1n4jap",
    "Rxw_gopM4jar",
    "eqCDCbcw4jas",
    "oBKJaFU24jas",
    "1aimb6bn4jat",
    "yZGY1eL84jau",
    "rxM3jQuK_Pqc",
    "GMReRXdH_YUd",
    "chN8hbfThKyr",
    "HtPIiIS7hKyr",
    "D9JNnpxa4jau",
    "d_pDMFAz4jav",
    "TM6VZTRn4jav",
    "c5hPmHyR4jaw"
   ],
   "name": "MT_Project_LearnerNotebook_FullCode (11).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
